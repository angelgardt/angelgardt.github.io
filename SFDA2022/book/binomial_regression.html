<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>17 Обобщенные линейные модели. Логистическая регрессия | Статистика для анализа данных</title>
  <meta name="description" content="Книжка для студентов бакалавриата «Психология» НИУ ВШЭ по курсу «Статистика для анализа данных»" />
  <meta name="generator" content="bookdown 0.29 and GitBook 2.6.7" />

  <meta property="og:title" content="17 Обобщенные линейные модели. Логистическая регрессия | Статистика для анализа данных" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Книжка для студентов бакалавриата «Психология» НИУ ВШЭ по курсу «Статистика для анализа данных»" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="17 Обобщенные линейные модели. Логистическая регрессия | Статистика для анализа данных" />
  
  <meta name="twitter:description" content="Книжка для студентов бакалавриата «Психология» НИУ ВШЭ по курсу «Статистика для анализа данных»" />
  

<meta name="author" content="Антон Ангельгардт" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="ancova.html"/>
<link rel="next" href="final.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">СДАД 2022</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Врубаем тэхно для рабочего настроения</a></li>
<li class="part"><span><b>I Введение в статистику</b></span></li>
<li class="chapter" data-level="1" data-path="intro_stats.html"><a href="intro_stats.html"><i class="fa fa-check"></i><b>1</b> Введение в статистику</a>
<ul>
<li class="chapter" data-level="1.1" data-path="intro_stats.html"><a href="intro_stats.html#stat_terms"><i class="fa fa-check"></i><b>1.1</b> Исходные понятия статистики</a></li>
<li class="chapter" data-level="1.2" data-path="intro_stats.html"><a href="intro_stats.html#why_we_need_statistics"><i class="fa fa-check"></i><b>1.2</b> Зачем нужна статистика?</a></li>
<li class="chapter" data-level="1.3" data-path="intro_stats.html"><a href="intro_stats.html#representative_sample"><i class="fa fa-check"></i><b>1.3</b> Выборка должна быть репрезентативна</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="intro_stats.html"><a href="intro_stats.html#how_to_recruit_sample"><i class="fa fa-check"></i><b>1.3.1</b> Как набрать репрезентативную выборку</a></li>
<li class="chapter" data-level="1.3.2" data-path="intro_stats.html"><a href="intro_stats.html#способы-формирования-репрезентативной-выборки"><i class="fa fa-check"></i><b>1.3.2</b> Способы формирования репрезентативной выборки</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="scales_random_vars.html"><a href="scales_random_vars.html"><i class="fa fa-check"></i><b>2</b> Шкалы. Случайные величины. Распределения</a>
<ul>
<li class="chapter" data-level="2.1" data-path="scales_random_vars.html"><a href="scales_random_vars.html#intro_scales"><i class="fa fa-check"></i><b>2.1</b> Вспомним, что</a></li>
<li class="chapter" data-level="2.2" data-path="scales_random_vars.html"><a href="scales_random_vars.html#measuring"><i class="fa fa-check"></i><b>2.2</b> Измерение в социальных науках</a></li>
<li class="chapter" data-level="2.3" data-path="scales_random_vars.html"><a href="scales_random_vars.html#feaures_variables"><i class="fa fa-check"></i><b>2.3</b> Признаки и переменные</a></li>
<li class="chapter" data-level="2.4" data-path="scales_random_vars.html"><a href="scales_random_vars.html#scales"><i class="fa fa-check"></i><b>2.4</b> Шкалы</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="scales_random_vars.html"><a href="scales_random_vars.html#why_we_need_scales"><i class="fa fa-check"></i><b>2.4.1</b> Зачем нам знать виды шкал?</a></li>
<li class="chapter" data-level="2.4.2" data-path="scales_random_vars.html"><a href="scales_random_vars.html#types_of_scales"><i class="fa fa-check"></i><b>2.4.2</b> Типы шкал</a></li>
<li class="chapter" data-level="2.4.3" data-path="scales_random_vars.html"><a href="scales_random_vars.html#arrange_scales"><i class="fa fa-check"></i><b>2.4.3</b> Порядок шкал по мощности</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="scales_random_vars.html"><a href="scales_random_vars.html#random_valiables"><i class="fa fa-check"></i><b>2.5</b> Случайные величины</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="scales_random_vars.html"><a href="scales_random_vars.html#rand_exp"><i class="fa fa-check"></i><b>2.5.1</b> Случайный эксперимент. Исходы случайного эксперимента</a></li>
<li class="chapter" data-level="2.5.2" data-path="scales_random_vars.html"><a href="scales_random_vars.html#rand_var"><i class="fa fa-check"></i><b>2.5.2</b> Случайная величина</a></li>
<li class="chapter" data-level="2.5.3" data-path="scales_random_vars.html"><a href="scales_random_vars.html#дискретные-случайные-величины"><i class="fa fa-check"></i><b>2.5.3</b> Дискретные случайные величины</a></li>
<li class="chapter" data-level="2.5.4" data-path="scales_random_vars.html"><a href="scales_random_vars.html#непрерывные-случайные-величины"><i class="fa fa-check"></i><b>2.5.4</b> Непрерывные случайные величины</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Описательная статистика</b></span></li>
<li class="chapter" data-level="3" data-path="central_tendency.html"><a href="central_tendency.html"><i class="fa fa-check"></i><b>3</b> Меры центральной тенденции</a>
<ul>
<li class="chapter" data-level="3.1" data-path="central_tendency.html"><a href="central_tendency.html#types_of_statistics"><i class="fa fa-check"></i><b>3.1</b> Виды статистики</a></li>
<li class="chapter" data-level="3.2" data-path="central_tendency.html"><a href="central_tendency.html#central_tendency_measures"><i class="fa fa-check"></i><b>3.2</b> Меры центральной тенденции</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="central_tendency.html"><a href="central_tendency.html#mode"><i class="fa fa-check"></i><b>3.2.1</b> Мода</a></li>
<li class="chapter" data-level="3.2.2" data-path="central_tendency.html"><a href="central_tendency.html#медиана"><i class="fa fa-check"></i><b>3.2.2</b> Медиана</a></li>
<li class="chapter" data-level="3.2.3" data-path="central_tendency.html"><a href="central_tendency.html#среднее-арифметическое"><i class="fa fa-check"></i><b>3.2.3</b> Среднее арифметическое</a></li>
<li class="chapter" data-level="3.2.4" data-path="central_tendency.html"><a href="central_tendency.html#другие-средние"><i class="fa fa-check"></i><b>3.2.4</b> Другие средние</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="central_tendency.html"><a href="central_tendency.html#сравнение-мер-центральной-тенденции"><i class="fa fa-check"></i><b>3.3</b> Сравнение мер центральной тенденции</a></li>
<li class="chapter" data-level="3.4" data-path="central_tendency.html"><a href="central_tendency.html#mean_features"><i class="fa fa-check"></i><b>3.4</b> Свойства среднего арифметического</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="variation.html"><a href="variation.html"><i class="fa fa-check"></i><b>4</b> Меры разброса</a>
<ul>
<li class="chapter" data-level="4.1" data-path="variation.html"><a href="variation.html#why_we_need_variation"><i class="fa fa-check"></i><b>4.1</b> Зачем нужны меры разброса</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="variation.html"><a href="variation.html#key_features_of_data"><i class="fa fa-check"></i><b>4.1.1</b> Основные характеристики статистических данных</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="variation.html"><a href="variation.html#range"><i class="fa fa-check"></i><b>4.2</b> Минимум, максимум, размах</a></li>
<li class="chapter" data-level="4.3" data-path="variation.html"><a href="variation.html#quantiles"><i class="fa fa-check"></i><b>4.3</b> Квантили</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="variation.html"><a href="variation.html#quartiles"><i class="fa fa-check"></i><b>4.3.1</b> Квартили</a></li>
<li class="chapter" data-level="4.3.2" data-path="variation.html"><a href="variation.html#deciles"><i class="fa fa-check"></i><b>4.3.2</b> Децили</a></li>
<li class="chapter" data-level="4.3.3" data-path="variation.html"><a href="variation.html#percentiles"><i class="fa fa-check"></i><b>4.3.3</b> Перцентили</a></li>
<li class="chapter" data-level="4.3.4" data-path="variation.html"><a href="variation.html#iqr"><i class="fa fa-check"></i><b>4.3.4</b> Интерквартильный размах</a></li>
<li class="chapter" data-level="4.3.5" data-path="variation.html"><a href="variation.html#boxplot"><i class="fa fa-check"></i><b>4.3.5</b> Визуализация квартилей. Боксплот</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="variation.html"><a href="variation.html#var"><i class="fa fa-check"></i><b>4.4</b> Дисперсия</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="variation.html"><a href="variation.html#degrees_of_freedom"><i class="fa fa-check"></i><b>4.4.1</b> Степени свободы</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="variation.html"><a href="variation.html#sd"><i class="fa fa-check"></i><b>4.5</b> Стандартное отклонение</a></li>
<li class="chapter" data-level="4.6" data-path="variation.html"><a href="variation.html#variation_comparison"><i class="fa fa-check"></i><b>4.6</b> Сравнение мер разброса</a></li>
<li class="chapter" data-level="4.7" data-path="variation.html"><a href="variation.html#var_features"><i class="fa fa-check"></i><b>4.7</b> Свойства дисперсии и стандартного отклонения</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="normal_distribution.html"><a href="normal_distribution.html"><i class="fa fa-check"></i><b>5</b> Нормальное распределение</a>
<ul>
<li class="chapter" data-level="5.1" data-path="normal_distribution.html"><a href="normal_distribution.html#distributions"><i class="fa fa-check"></i><b>5.1</b> Распределение признаков в генеральной совокупности</a></li>
<li class="chapter" data-level="5.2" data-path="normal_distribution.html"><a href="normal_distribution.html#norm_dist"><i class="fa fa-check"></i><b>5.2</b> Нормальное распределение</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="normal_distribution.html"><a href="normal_distribution.html#norm_params"><i class="fa fa-check"></i><b>5.2.1</b> Параметры нормального распределения</a></li>
<li class="chapter" data-level="5.2.2" data-path="normal_distribution.html"><a href="normal_distribution.html#in_love_with_norm_dist"><i class="fa fa-check"></i><b>5.2.2</b> Почему все так любят нормальное распределение?</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="normal_distribution.html"><a href="normal_distribution.html#norm_shapes"><i class="fa fa-check"></i><b>5.3</b> Форма нормального распределения и параметры</a></li>
<li class="chapter" data-level="5.4" data-path="normal_distribution.html"><a href="normal_distribution.html#стандартные-отклонения-и-вероятности"><i class="fa fa-check"></i><b>5.4</b> Стандартные отклонения и вероятности</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="standardization.html"><a href="standardization.html"><i class="fa fa-check"></i><b>6</b> Стандартизация</a>
<ul>
<li class="chapter" data-level="6.1" data-path="standardization.html"><a href="standardization.html#стандартное-нормальное-распределение"><i class="fa fa-check"></i><b>6.1</b> Стандартное нормальное распределение</a></li>
<li class="chapter" data-level="6.2" data-path="standardization.html"><a href="standardization.html#стандартизация"><i class="fa fa-check"></i><b>6.2</b> Стандартизация</a></li>
<li class="chapter" data-level="6.3" data-path="standardization.html"><a href="standardization.html#интерпретация-z-значений"><i class="fa fa-check"></i><b>6.3</b> Интерпретация z-значений</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="clt_ci.html"><a href="clt_ci.html"><i class="fa fa-check"></i><b>7</b> Центральная предельная теорема и доверительные интервалы</a>
<ul>
<li class="chapter" data-level="7.1" data-path="clt_ci.html"><a href="clt_ci.html#interval_estim"><i class="fa fa-check"></i><b>7.1</b> Точечные и интервальные оценки</a></li>
<li class="chapter" data-level="7.2" data-path="clt_ci.html"><a href="clt_ci.html#clt"><i class="fa fa-check"></i><b>7.2</b> Центральная предельная теорема</a></li>
<li class="chapter" data-level="7.3" data-path="clt_ci.html"><a href="clt_ci.html#mean_se"><i class="fa fa-check"></i><b>7.3</b> Стандартная ошибка среднего</a></li>
<li class="chapter" data-level="7.4" data-path="clt_ci.html"><a href="clt_ci.html#mean_ci"><i class="fa fa-check"></i><b>7.4</b> Доверительные интервалы</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="clt_ci.html"><a href="clt_ci.html#ci_interpretation"><i class="fa fa-check"></i><b>7.4.1</b> Интерпретация границ доверительного интервала</a></li>
<li class="chapter" data-level="7.4.2" data-path="clt_ci.html"><a href="clt_ci.html#mean_ci_comp"><i class="fa fa-check"></i><b>7.4.2</b> Доверительный интервал и сравнение средних</a></li>
<li class="chapter" data-level="7.4.3" data-path="clt_ci.html"><a href="clt_ci.html#ci_se_sample_size"><i class="fa fa-check"></i><b>7.4.3</b> Связь доверительного интервала с разбросом и объемом выборки</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Статистика вывода и статметоды</b></span></li>
<li class="chapter" data-level="8" data-path="nhst.html"><a href="nhst.html"><i class="fa fa-check"></i><b>8</b> Тестирование статистических гипотез</a>
<ul>
<li class="chapter" data-level="8.1" data-path="nhst.html"><a href="nhst.html#базовые-понятия"><i class="fa fa-check"></i><b>8.1</b> Базовые понятия</a></li>
<li class="chapter" data-level="8.2" data-path="nhst.html"><a href="nhst.html#errors"><i class="fa fa-check"></i><b>8.2</b> Возможные результаты проверки гипотез</a></li>
<li class="chapter" data-level="8.3" data-path="nhst.html"><a href="nhst.html#stat_test_asymm"><i class="fa fa-check"></i><b>8.3</b> Асимметрия статистического вывода</a></li>
<li class="chapter" data-level="8.4" data-path="nhst.html"><a href="nhst.html#stat_test_algorithm"><i class="fa fa-check"></i><b>8.4</b> Алгоритм тестирования статистических гипотез</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="chisq.html"><a href="chisq.html"><i class="fa fa-check"></i><b>9</b> Анализ категориальных данных</a>
<ul>
<li class="chapter" data-level="9.1" data-path="chisq.html"><a href="chisq.html#crosstab"><i class="fa fa-check"></i><b>9.1</b> Таблица сопряженности</a></li>
<li class="chapter" data-level="9.2" data-path="chisq.html"><a href="chisq.html#theor_freq"><i class="fa fa-check"></i><b>9.2</b> Расчёт теоретических частот</a></li>
<li class="chapter" data-level="9.3" data-path="chisq.html"><a href="chisq.html#chisq_test"><i class="fa fa-check"></i><b>9.3</b> Критерий независимости Пирсона</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="chisq.html"><a href="chisq.html#распределение-chi2"><i class="fa fa-check"></i><b>9.3.1</b> Распределение <span class="math inline">\(\chi^2\)</span></a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="chisq.html"><a href="chisq.html#критерий-согласия-пирсона"><i class="fa fa-check"></i><b>9.4</b> Критерий согласия Пирсона</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="correlations.html"><a href="correlations.html"><i class="fa fa-check"></i><b>10</b> Корреляционный анализ</a>
<ul>
<li class="chapter" data-level="10.1" data-path="correlations.html"><a href="correlations.html#covariance"><i class="fa fa-check"></i><b>10.1</b> Ковариация</a></li>
<li class="chapter" data-level="10.2" data-path="correlations.html"><a href="correlations.html#correlation"><i class="fa fa-check"></i><b>10.2</b> Корреляция</a></li>
<li class="chapter" data-level="10.3" data-path="correlations.html"><a href="correlations.html#pearson_corr"><i class="fa fa-check"></i><b>10.3</b> Корреляция Пирсона</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="correlations.html"><a href="correlations.html#corr_test"><i class="fa fa-check"></i><b>10.3.1</b> Тестирование статистической значимости коэффициента корреляции</a></li>
<li class="chapter" data-level="10.3.2" data-path="correlations.html"><a href="correlations.html#cor_ci"><i class="fa fa-check"></i><b>10.3.2</b> Доверительный интервал для коэффициента корреляции</a></li>
<li class="chapter" data-level="10.3.3" data-path="correlations.html"><a href="correlations.html#effect_size_cor"><i class="fa fa-check"></i><b>10.3.3</b> Размер эффекта для коэффициента корреляции</a></li>
<li class="chapter" data-level="10.3.4" data-path="correlations.html"><a href="correlations.html#power_corr"><i class="fa fa-check"></i><b>10.3.4</b> Расчет объема выборки для корреляционного анализа</a></li>
<li class="chapter" data-level="10.3.5" data-path="correlations.html"><a href="correlations.html#cor_vis"><i class="fa fa-check"></i><b>10.3.5</b> Визуализация корреляции</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="correlations.html"><a href="correlations.html#corr_coefs"><i class="fa fa-check"></i><b>10.4</b> Коэффициенты корреляции для разных шкал</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="correlations.html"><a href="correlations.html#param_vs_nonparam"><i class="fa fa-check"></i><b>10.4.1</b> Параметрические и непараметрические критерии</a></li>
<li class="chapter" data-level="10.4.2" data-path="correlations.html"><a href="correlations.html#nonparam_corr"><i class="fa fa-check"></i><b>10.4.2</b> Непараметрические коэффициенты корреляции</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="correlations.html"><a href="correlations.html#other_cor"><i class="fa fa-check"></i><b>10.5</b> Другие корреляции</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="correlations.html"><a href="correlations.html#phi_coef"><i class="fa fa-check"></i><b>10.5.1</b> <span class="math inline">\(\phi\)</span>-коэффициент</a></li>
<li class="chapter" data-level="10.5.2" data-path="correlations.html"><a href="correlations.html#biserial_cor"><i class="fa fa-check"></i><b>10.5.2</b> Бисериальный коэффициент корреляции</a></li>
<li class="chapter" data-level="10.5.3" data-path="correlations.html"><a href="correlations.html#rank_biserial_cor"><i class="fa fa-check"></i><b>10.5.3</b> Рангово-бисериальный коэффициент корреляции</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="oneway-anova.html"><a href="oneway-anova.html"><i class="fa fa-check"></i><b>11</b> Общие линейные модели. Однофакторный дисперсионный анализ</a>
<ul>
<li class="chapter" data-level="11.1" data-path="oneway-anova.html"><a href="oneway-anova.html#experiment"><i class="fa fa-check"></i><b>11.1</b> Э-э-эксперимент</a></li>
<li class="chapter" data-level="11.2" data-path="oneway-anova.html"><a href="oneway-anova.html#var_struct"><i class="fa fa-check"></i><b>11.2</b> Структура изменчивости данных</a></li>
<li class="chapter" data-level="11.3" data-path="oneway-anova.html"><a href="oneway-anova.html#why_anova"><i class="fa fa-check"></i><b>11.3</b> Зачем нужен дисперсионный анализ?</a></li>
<li class="chapter" data-level="11.4" data-path="oneway-anova.html"><a href="oneway-anova.html#f_test"><i class="fa fa-check"></i><b>11.4</b> Тестирование значимости фактора</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="oneway-anova.html"><a href="oneway-anova.html#распределение-фишера"><i class="fa fa-check"></i><b>11.4.1</b> Распределение Фишера</a></li>
<li class="chapter" data-level="11.4.2" data-path="oneway-anova.html"><a href="oneway-anova.html#anova_results"><i class="fa fa-check"></i><b>11.4.2</b> Представление результатов дисперсионного анализа</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="oneway-anova.html"><a href="oneway-anova.html#eta_sq"><i class="fa fa-check"></i><b>11.5</b> Размер эффекта в дисперсионном анализе</a></li>
<li class="chapter" data-level="11.6" data-path="oneway-anova.html"><a href="oneway-anova.html#anova_vis"><i class="fa fa-check"></i><b>11.6</b> Визуализация результатов дисперсионного анализа</a></li>
<li class="chapter" data-level="11.7" data-path="oneway-anova.html"><a href="oneway-anova.html#anova_require"><i class="fa fa-check"></i><b>11.7</b> Условия применения дисперсионного анализа</a>
<ul>
<li class="chapter" data-level="11.7.1" data-path="oneway-anova.html"><a href="oneway-anova.html#homogenity"><i class="fa fa-check"></i><b>11.7.1</b> Гомогенность дисперсий</a></li>
</ul></li>
<li class="chapter" data-level="11.8" data-path="oneway-anova.html"><a href="oneway-anova.html#anova_effects"><i class="fa fa-check"></i><b>11.8</b> Виды эффектов в дисперсионном анализе</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="twoway-anova.html"><a href="twoway-anova.html"><i class="fa fa-check"></i><b>12</b> Многофакторный дисперионный анализ</a>
<ul>
<li class="chapter" data-level="12.1" data-path="twoway-anova.html"><a href="twoway-anova.html#experiment2"><i class="fa fa-check"></i><b>12.1</b> Усложняем э-э-эксперимент</a></li>
<li class="chapter" data-level="12.2" data-path="twoway-anova.html"><a href="twoway-anova.html#factor_interaction"><i class="fa fa-check"></i><b>12.2</b> Взаимодействие факторов</a></li>
<li class="chapter" data-level="12.3" data-path="twoway-anova.html"><a href="twoway-anova.html#twoway_results"><i class="fa fa-check"></i><b>12.3</b> Результаты многофакторного дисперсионного анализа и тестирование значимости факторов и взаимодействий</a></li>
<li class="chapter" data-level="12.4" data-path="twoway-anova.html"><a href="twoway-anova.html#rmanova_require"><i class="fa fa-check"></i><b>12.4</b> Условия применения дисперсионного анализа с повторными измерениям</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="twoway-anova.html"><a href="twoway-anova.html#sphericity"><i class="fa fa-check"></i><b>12.4.1</b> Сферичность</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="twoway-anova.html"><a href="twoway-anova.html#type_of_sums"><i class="fa fa-check"></i><b>12.5</b> Типы сумм квадратов</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="post_hoc.html"><a href="post_hoc.html"><i class="fa fa-check"></i><b>13</b> Post hoc тесты. Критерий Стьюдента. Проблема множественных сравнений</a>
<ul>
<li class="chapter" data-level="13.1" data-path="post_hoc.html"><a href="post_hoc.html#pairwise_comp"><i class="fa fa-check"></i><b>13.1</b> Попарные сравнения</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="post_hoc.html"><a href="post_hoc.html#multiple_comp"><i class="fa fa-check"></i><b>13.1.1</b> Проблема множественных сравнений</a></li>
<li class="chapter" data-level="13.1.2" data-path="post_hoc.html"><a href="post_hoc.html#p-adj"><i class="fa fa-check"></i><b>13.1.2</b> Корректировка уровня значимости</a></li>
<li class="chapter" data-level="13.1.3" data-path="post_hoc.html"><a href="post_hoc.html#anova_vs_mult_comp"><i class="fa fa-check"></i><b>13.1.3</b> Дисперсионный анализ и проблема множественных сравнений</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="post_hoc.html"><a href="post_hoc.html#t-test"><i class="fa fa-check"></i><b>13.2</b> Двухвыборочный t-тест</a></li>
<li class="chapter" data-level="13.3" data-path="post_hoc.html"><a href="post_hoc.html#paired-t-test"><i class="fa fa-check"></i><b>13.3</b> Парный t-тест</a></li>
<li class="chapter" data-level="13.4" data-path="post_hoc.html"><a href="post_hoc.html#post_hoc_test"><i class="fa fa-check"></i><b>13.4</b> Че за post hoc?</a></li>
<li class="chapter" data-level="13.5" data-path="post_hoc.html"><a href="post_hoc.html#t-test-per-se"><i class="fa fa-check"></i><b>13.5</b> t-тест — сильный и независимый</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="simple_linear.html"><a href="simple_linear.html"><i class="fa fa-check"></i><b>14</b> Простая линейная регрессия</a>
<ul>
<li class="chapter" data-level="14.1" data-path="simple_linear.html"><a href="simple_linear.html#simple_reg_formalization"><i class="fa fa-check"></i><b>14.1</b> Формализация модели</a></li>
<li class="chapter" data-level="14.2" data-path="simple_linear.html"><a href="simple_linear.html#simple_reg_indentification"><i class="fa fa-check"></i><b>14.2</b> Идентификация модели</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="simple_linear.html"><a href="simple_linear.html#least-squares"><i class="fa fa-check"></i><b>14.2.1</b> Метод наименьших квадратов</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="simple_linear.html"><a href="simple_linear.html#simple_reg_quality"><i class="fa fa-check"></i><b>14.3</b> Тестирование качества модели</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="simple_linear.html"><a href="simple_linear.html#r-squared"><i class="fa fa-check"></i><b>14.3.1</b> Коэффициент детерминации</a></li>
<li class="chapter" data-level="14.3.2" data-path="simple_linear.html"><a href="simple_linear.html#simple_reg_significance"><i class="fa fa-check"></i><b>14.3.2</b> Статистическая значимость модели</a></li>
<li class="chapter" data-level="14.3.3" data-path="simple_linear.html"><a href="simple_linear.html#simple_reg_t_test"><i class="fa fa-check"></i><b>14.3.3</b> Статистическая значимость отдельных предикторов</a></li>
<li class="chapter" data-level="14.3.4" data-path="simple_linear.html"><a href="simple_linear.html#simple_regression_results"><i class="fa fa-check"></i><b>14.3.4</b> Результаты регрессионного анализа</a></li>
<li class="chapter" data-level="14.3.5" data-path="simple_linear.html"><a href="simple_linear.html#slope_interpretation_simple_linear"><i class="fa fa-check"></i><b>14.3.5</b> Интерпретация коэффициента при предикторе</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="simple_linear.html"><a href="simple_linear.html#simple_reg_diagnostics"><i class="fa fa-check"></i><b>14.4</b> Диагностика модели</a></li>
<li class="chapter" data-level="14.5" data-path="simple_linear.html"><a href="simple_linear.html#corr_vs_lm"><i class="fa fa-check"></i><b>14.5</b> Корреляция vs регрессия</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="multiple_linear.html"><a href="multiple_linear.html"><i class="fa fa-check"></i><b>15</b> Множественная линейная регрессия</a>
<ul>
<li class="chapter" data-level="15.1" data-path="multiple_linear.html"><a href="multiple_linear.html#several_predictors"><i class="fa fa-check"></i><b>15.1</b> Связи между несколькими переменными</a></li>
<li class="chapter" data-level="15.2" data-path="multiple_linear.html"><a href="multiple_linear.html#multiple_linear_quanti"><i class="fa fa-check"></i><b>15.2</b> Множественная линейная регрессия с количественными предикторами</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="multiple_linear.html"><a href="multiple_linear.html#multicollinearity"><i class="fa fa-check"></i><b>15.2.1</b> Проблема мультиколлинеарности</a></li>
<li class="chapter" data-level="15.2.2" data-path="multiple_linear.html"><a href="multiple_linear.html#multiple_linear_results"><i class="fa fa-check"></i><b>15.2.2</b> Результаты множественной линейной регрессии</a></li>
<li class="chapter" data-level="15.2.3" data-path="multiple_linear.html"><a href="multiple_linear.html#r_squared_adjusted"><i class="fa fa-check"></i><b>15.2.3</b> Скорректированный <span class="math inline">\(R^2\)</span></a></li>
<li class="chapter" data-level="15.2.4" data-path="multiple_linear.html"><a href="multiple_linear.html#vif"><i class="fa fa-check"></i><b>15.2.4</b> Исследование мультиколлинеарности</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="multiple_linear.html"><a href="multiple_linear.html#multiple_linear_quali_quanti"><i class="fa fa-check"></i><b>15.3</b> Множественная линейная регрессия с количественными и категориальными предикторами</a>
<ul>
<li class="chapter" data-level="15.3.1" data-path="multiple_linear.html"><a href="multiple_linear.html#multiple_linear_quali_quanti_model"><i class="fa fa-check"></i><b>15.3.1</b> Математическая модель</a></li>
<li class="chapter" data-level="15.3.2" data-path="multiple_linear.html"><a href="multiple_linear.html#multiple_linear_quali_quanti_results"><i class="fa fa-check"></i><b>15.3.2</b> Результаты множественной линейной регрессии с количественными и категориальными предикторами</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="multiple_linear.html"><a href="multiple_linear.html#predictor_interaction"><i class="fa fa-check"></i><b>15.4</b> Модели со взаимодействием предикторов</a></li>
<li class="chapter" data-level="15.5" data-path="multiple_linear.html"><a href="multiple_linear.html#regression_anova"><i class="fa fa-check"></i><b>15.5</b> Линейная регрессия только с категориальными предикторами</a>
<ul>
<li class="chapter" data-level="15.5.1" data-path="multiple_linear.html"><a href="multiple_linear.html#regression_oneway_anova"><i class="fa fa-check"></i><b>15.5.1</b> Простая линейная регрессия только с категориальными предикторами</a></li>
<li class="chapter" data-level="15.5.2" data-path="multiple_linear.html"><a href="multiple_linear.html#regression_twoway_anova"><i class="fa fa-check"></i><b>15.5.2</b> Множественная линейная регрессия только с категориальными предикторами</a></li>
</ul></li>
<li class="chapter" data-level="15.6" data-path="multiple_linear.html"><a href="multiple_linear.html#model_comparison"><i class="fa fa-check"></i><b>15.6</b> Сравнение моделей</a>
<ul>
<li class="chapter" data-level="15.6.1" data-path="multiple_linear.html"><a href="multiple_linear.html#r_squared_comparison"><i class="fa fa-check"></i><b>15.6.1</b> Коэффициент детерминации</a></li>
<li class="chapter" data-level="15.6.2" data-path="multiple_linear.html"><a href="multiple_linear.html#F_partial"><i class="fa fa-check"></i><b>15.6.2</b> Частный F-критерий</a></li>
<li class="chapter" data-level="15.6.3" data-path="multiple_linear.html"><a href="multiple_linear.html#mse_rmse_mae"><i class="fa fa-check"></i><b>15.6.3</b> Ошибки моделей</a></li>
<li class="chapter" data-level="15.6.4" data-path="multiple_linear.html"><a href="multiple_linear.html#bic_aic"><i class="fa fa-check"></i><b>15.6.4</b> Информационные критерии</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="ancova.html"><a href="ancova.html"><i class="fa fa-check"></i><b>16</b> Ковариационный анализ</a>
<ul>
<li class="chapter" data-level="16.1" data-path="ancova.html"><a href="ancova.html#ancova_model"><i class="fa fa-check"></i><b>16.1</b> Модель ковариационного анализа</a></li>
<li class="chapter" data-level="16.2" data-path="ancova.html"><a href="ancova.html#covariate_role"><i class="fa fa-check"></i><b>16.2</b> Влияние ковариаты</a></li>
<li class="chapter" data-level="16.3" data-path="ancova.html"><a href="ancova.html#ancova_tests"><i class="fa fa-check"></i><b>16.3</b> Тестирование значимости предикторов и диагностика модели</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="binomial_regression.html"><a href="binomial_regression.html"><i class="fa fa-check"></i><b>17</b> Обобщенные линейные модели. Логистическая регрессия</a>
<ul>
<li class="chapter" data-level="17.1" data-path="binomial_regression.html"><a href="binomial_regression.html#lm_restrictions"><i class="fa fa-check"></i><b>17.1</b> Ограничения общих линейных моделей</a></li>
<li class="chapter" data-level="17.2" data-path="binomial_regression.html"><a href="binomial_regression.html#binary_vars"><i class="fa fa-check"></i><b>17.2</b> Бинарные переменные</a></li>
<li class="chapter" data-level="17.3" data-path="binomial_regression.html"><a href="binomial_regression.html#managers_data"><i class="fa fa-check"></i><b>17.3</b> Данные</a></li>
<li class="chapter" data-level="17.4" data-path="binomial_regression.html"><a href="binomial_regression.html#binom_problem"><i class="fa fa-check"></i><b>17.4</b> Задача построения линейной модели</a></li>
<li class="chapter" data-level="17.5" data-path="binomial_regression.html"><a href="binomial_regression.html#glm_magic"><i class="fa fa-check"></i><b>17.5</b> Переход от дискретной величины к непрерывной</a>
<ul>
<li class="chapter" data-level="17.5.1" data-path="binomial_regression.html"><a href="binomial_regression.html#logistic_curve"><i class="fa fa-check"></i><b>17.5.1</b> Логистическая кривая</a></li>
<li class="chapter" data-level="17.5.2" data-path="binomial_regression.html"><a href="binomial_regression.html#odds"><i class="fa fa-check"></i><b>17.5.2</b> Шансы и логиты</a></li>
</ul></li>
<li class="chapter" data-level="17.6" data-path="binomial_regression.html"><a href="binomial_regression.html#binom_model"><i class="fa fa-check"></i><b>17.6</b> Математическая модель</a></li>
<li class="chapter" data-level="17.7" data-path="binomial_regression.html"><a href="binomial_regression.html#binom_results"><i class="fa fa-check"></i><b>17.7</b> Результаты логистической регрессии</a></li>
<li class="chapter" data-level="17.8" data-path="binomial_regression.html"><a href="binomial_regression.html#binom_model_analysis"><i class="fa fa-check"></i><b>17.8</b> Анализ модели</a>
<ul>
<li class="chapter" data-level="17.8.1" data-path="binomial_regression.html"><a href="binomial_regression.html#z-test"><i class="fa fa-check"></i><b>17.8.1</b> Тест Вальда</a></li>
<li class="chapter" data-level="17.8.2" data-path="binomial_regression.html"><a href="binomial_regression.html#deviance_analysis"><i class="fa fa-check"></i><b>17.8.2</b> Анализ девиансы и статистическая значимость модели</a></li>
</ul></li>
<li class="chapter" data-level="17.9" data-path="binomial_regression.html"><a href="binomial_regression.html#coef_interpretation_binom"><i class="fa fa-check"></i><b>17.9</b> Интерпретация коэффициентов модели</a>
<ul>
<li class="chapter" data-level="17.9.1" data-path="binomial_regression.html"><a href="binomial_regression.html#algebra_ln"><i class="fa fa-check"></i><b>17.9.1</b> Немного алгебры для понимания сути коэффициентов</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="final.html"><a href="final.html"><i class="fa fa-check"></i>Вырубаем тэхно, врубаем дип хаус</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Статистика для анализа данных</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="binomial_regression" class="section level1 hasAnchor" number="17">
<h1><span class="header-section-number">17</span> Обобщенные линейные модели. Логистическая регрессия<a href="binomial_regression.html#binomial_regression" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="lm_restrictions" class="section level2 hasAnchor" number="17.1">
<h2><span class="header-section-number">17.1</span> Ограничения общих линейных моделей<a href="binomial_regression.html#lm_restrictions" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Модели, которые мы изучали на предыдущих занятиях носят название <strong>общих линейных моделей (general linear models)</strong>. Они достаточно просты и удобны в большинстве случаев, однако имеют ряд важных ограничений.</p>
<p>Вспомним, как выглядит уравнение такой модели:</p>
<p><span class="math display">\[y = \beta_0 + \beta_1 x_1 + \dots + \beta_p x_p + \varepsilon\]</span></p>
<p>Предикторы в такой модели могут быть как дискретными, так и непрерывными.</p>
<p>Важнейшим допущением и требованием этой модели является распределение ошибки:</p>
<p><span class="math display">\[\varepsilon \thicksim \mathcal{N}(0, \, \sigma)\]</span></p>
<p>Поскольку ошибка модели должна быть распределена нормально, а моделируется среднее значение, то можно сформулировать более общее допущение / требование:</p>
<p><span class="math display">\[y_i \thicksim \mathcal{N}(\mu_i, \, \sigma)\]</span></p>
<p>Таким образом, общие линейные модели позволяют моделировать зависимости только для нормальнораспределенных величин. Если же наша целевая переменная подчиняется другому распределению, эти модели не годятся.</p>
<p>Однако нам на помощь приходят <strong>обобщенные линейные модели (generalized linear models)</strong>, которые позволяют моделировать зависимости величин, подчиняющихся не только нормальному распределению, но и многим другим.</p>
<p>Мы познакомимся с общей логикой построения GLM, подробно рассмотрев один из вариантов таких моделей, а именно <strong>биномиальную регрессию</strong>.</p>
</div>
<div id="binary_vars" class="section level2 hasAnchor" number="17.2">
<h2><span class="header-section-number">17.2</span> Бинарные переменные<a href="binomial_regression.html#binary_vars" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Эти переменные достаточно широко распространены как повседневности, так и в науке. Блюдо вкусное или невкусное, команда выиграла или проиграла, пациент в результате медицинских манипуляций выжил или умер, в ходе эксперимента была выбрана какая-то опция или нет, сдал студент экзамен или не сдал — и т.д.</p>
<p>Эти события могут быть связаны с раздичными предикторами, и такую взаимосвязь можно описать с помощью регрессионных моделей.</p>
</div>
<div id="managers_data" class="section level2 hasAnchor" number="17.3">
<h2><span class="header-section-number">17.3</span> Данные<a href="binomial_regression.html#managers_data" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Снова начнем с данных — на этот раз про менеджеров. Это часть данных большого датасета, собранного в рамках одного из HR-исследований.</p>
<pre><code>## # A tibble: 6 × 10
##   id       lvl   quali…¹ auton…² subdi…³ compa…⁴ direc…⁵ func_…⁶ incom…⁷ error…⁸
##   &lt;chr&gt;    &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;
## 1 таб_154… Сотр…       5       2       1       1       1       1       1       1
## 2 таб_139… Сотр…       4       2       1       1       1       1       1       2
## 3 таб_407… Сотр…       2       2       1       1       1       1       1       1
## 4 таб_417… Сотр…       4       3       1       1       1       1       1       1
## 5 таб_633… Мене…       5       3       2       3       2       1       3       5
## 6 таб_162… Сотр…       2       2       1       1       1       1       2       2
## # … with abbreviated variable names ¹​qualification, ²​autonomy,
## #   ³​subdiv_regulations, ⁴​company_regulations, ⁵​direct_juniors, ⁶​func_juniors,
## #   ⁷​income_influence, ⁸​error_cost</code></pre>
<p>У нас есть следуюшие переменные:</p>
<ul>
<li><code>id</code> — табельный номер сотрудника</li>
<li><code>lvl</code> — уровень (<code>Сотрудник</code> или <code>Менеджер</code>)</li>
<li><code>qualification</code> — профессиональная квалификация</li>
<li><code>autonomy</code> — автономия в принятии решений</li>
<li><code>subdiv_regulations</code> — участие в формировании регламентов подразделения</li>
<li><code>company_regulations</code> — участие в формировании регламентов Компании</li>
<li><code>direct_juniors</code> — количество прямых подчинённых</li>
<li><code>func_juniors</code> — количество функциональных подчинённых</li>
<li><code>income_influence</code> — влияние на доход Компании</li>
<li><code>error_cost</code> — стоимость ошибки</li>
</ul>
</div>
<div id="binom_problem" class="section level2 hasAnchor" number="17.4">
<h2><span class="header-section-number">17.4</span> Задача построения линейной модели<a href="binomial_regression.html#binom_problem" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>В наших данных есть бинарная переменная <code>lvl</code> — она содержит две градации: <code>Сотрудник</code> и <code>Менеджер</code>. Вопрос, на который нам необходимо ответить: по каким параметрам различаются менеджеры и сотрудники?</p>
<pre><code>## 
##  Менеджер Сотрудник 
##       810      2400</code></pre>
<p>Прежде всего надо вспомнить, что мы работаем с математической моделью, которой необходимы числа, поэтому придётся перекодировать нашу целевую переменную. Пусть <code>1</code> обозначает менеджеров, а <code>0</code> — сотрудников.</p>
<p>Теперь мы можем построить модель, описывающую связь <code>lvl</code> с имеющимися предикторами.</p>
<p>Попробуем обычную линейную регрессию.</p>
<pre><code>## 
## Call:
## lm(formula = lvl ~ ., data = managers)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.47532 -0.07671 -0.04250  0.06891  1.02042 
## 
## Coefficients:
##                      Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)         -0.869056   0.015520 -55.994  &lt; 2e-16 ***
## qualification        0.048487   0.004420  10.969  &lt; 2e-16 ***
## autonomy             0.016780   0.008309   2.019 0.043527 *  
## subdiv_regulations   0.281009   0.014017  20.048  &lt; 2e-16 ***
## company_regulations -0.068712   0.011403  -6.026 1.88e-09 ***
## direct_juniors       0.369140   0.012549  29.416  &lt; 2e-16 ***
## func_juniors         0.107304   0.008069  13.298  &lt; 2e-16 ***
## income_influence     0.072478   0.007434   9.749  &lt; 2e-16 ***
## error_cost          -0.026336   0.007985  -3.298 0.000984 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.2235 on 3201 degrees of freedom
## Multiple R-squared:  0.7361, Adjusted R-squared:  0.7354 
## F-statistic:  1116 on 8 and 3201 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Модель построилась, всё суперклассно.</p>
<p>Попробуем визуализировать, что получилось.</p>
<p><img src="SFDA_files/figure-html/lmbad-1.png" width="672" /></p>
<p>Но получается что-то странное…</p>
<p>Во-первых, непонятно, какая величина отложена на оси <span class="math inline">\(y\)</span>. Во-вторых, предсказания модели выходят за границы допустимых значений (модель предсказывает отрицательные и большие единицы значения). Поэтому простая линейная модель нам не подходит. Надо искать что-то еще.</p>
</div>
<div id="glm_magic" class="section level2 hasAnchor" number="17.5">
<h2><span class="header-section-number">17.5</span> Переход от дискретной величины к непрерывной<a href="binomial_regression.html#glm_magic" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="logistic_curve" class="section level3 hasAnchor" number="17.5.1">
<h3><span class="header-section-number">17.5.1</span> Логистическая кривая<a href="binomial_regression.html#logistic_curve" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Собственно бинарные переменные неудобны для работы, поэтому надо найти способ превратить такую дискретную бинарную шкалу в «безграничную» и непрерывную. При моделировании нулей и единиц переходят к моделированию <strong>вероятности получения единиц</strong>.</p>
<p>Сама зависимая переменная в зависимости от предиктора распределена примерно так:</p>
<center>
<img src="pics/predictor_binomial.jpeg">
</center>
<p>Введем новые обозначения:</p>
<ul>
<li><span class="math inline">\(p_i\)</span> — вероятность события <span class="math inline">\(y_i = 1\)</span> при данных значениях предиктора,</li>
<li><span class="math inline">\(1 - p_i\)</span> — вероятность альтернативного события <span class="math inline">\(y_i = 0\)</span>.</li>
</ul>
<p>Получается непрерывная величина <span class="math inline">\(0 \leq p_i \leq 1\)</span>.</p>
<center>
<img src="pics/prob_with_lm.jpeg">
</center>
<p>И вроде бы как ее можно уже моделировать. Но нужно помнить, что вероятность изменяется в пределах от нуля до единицы, а прямая ничем не ограничена. Поэтому прямая — не лучший вариант.</p>
<p>Такая закономерность моделируется логистической кривой.</p>
<center>
<img src="pics/logistic_curve_1.jpeg">
</center>
<p><img src="SFDA_files/figure-html/logistic_curve-1.png" width="672" /></p>
<p>Она лежит как раз в пределах от 0 до 1. Наша логистическая кривая задается уравнением</p>
<p><span class="math display">\[
p_i = \frac{e^{\beta_0 + \beta_1 x_i}}{1 + e^{\beta_0 + \beta_1 x_i}}
\]</span></p>
<p>Логистическую кривую мы больше никогда не увидим — печаль :( — но она используется внутри функций, которыми мы строим модель.</p>
</div>
<div id="odds" class="section level3 hasAnchor" number="17.5.2">
<h3><span class="header-section-number">17.5.2</span> Шансы и логиты<a href="binomial_regression.html#odds" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Теперь нам надо побороться с ограниченностью логистической кривой. Для этого можно перейти от вероятностей к шансам.</p>
<p><strong>Шанс (отношение шансов, odds, odds ratio)</strong> — это отношение вероятности успеха к вероятности неудачи. Их величина варьируется от <span class="math inline">\(0\)</span> до <span class="math inline">\(+\infty\)</span>.</p>
<p>Уже лучше, но все еще не самый лучший вариант… Последний шаг, необходимый нам, чтобы все было хорошо, юзануть логарифм, который преобразуем шансы в логиты.</p>
<p><span class="math display">\[
\mathrm{logit}(p) = \ln\left(\frac{p_i}{1-p_i}\right)
\]</span></p>
<p>Значения логитов — трансформированные оценки вероятностей события. Они варьируют от <span class="math inline">\(-\infty\)</span> до <span class="math inline">\(+\infty\)</span>, симметричны относительно нуля, и их удобно брать в качестве зависимой переменной для построения модели. Кроме того, logit-преобразование еще и <em>линеаризует</em> логистическую кривую, то есть превращает её в прямую.</p>
<div class="advanced">
<details>
<summary>
<em>И далет это примерно так</em>
</summary>
<p>Модель биномиальной регрессии с одним предиктором имеет следующий вид:</p>
<p><span class="math display">\[
p = \frac{e^{\beta_0 + \beta_1 x}}{1 + e^{\beta_0 + \beta_1 x}},
\]</span></p>
<p>где <span class="math inline">\(p\)</span> — вероятность «единицы», <span class="math inline">\(\beta_0\)</span> и <span class="math inline">\(\beta_1\)</span> — коэффициенты модели, <span class="math inline">\(x\)</span> — значение предиктора.</p>
<p>Обозначим <span class="math inline">\(\beta_0 + \beta_1 x = t\)</span>.</p>
<p>Необходимо доказать, что logit-преобразование</p>
<p><span class="math display">\[
\text{logit}(p) = \ln \left( \frac{p}{1 - p} \right)
\]</span></p>
<p>сделает логистическую функцию линейной — обычной прямое. Иначе говоря, необходимо доказать, что</p>
<p><span class="math display">\[
\ln \left( \frac{p}{1 - p} \right) = t
\]</span></p>
<p>Распишем формулу:</p>
<p><span class="math display">\[
\ln \left( \frac{p}{1 - p} \right) = \ln \left( \frac{\dfrac{e^t}{1 + e^t}}{1 - \dfrac{e^t}{1 + e^t}} \right) =
\]</span></p>
<p>Далее пользуемся свойствами логарифма:</p>
<p><span class="math display">\[
= \ln \left( \frac{e^t}{1 + e^t} \right) - \ln \left( 1 - \frac{e^t}{1 + e^t} \right) = \\
\ln \left( \frac{e^t}{1 + e^t} \right) - \ln \left( \frac{1 + e^t - e^t}{1 + e^t} \right) = \\
\ln \left( \frac{e^t}{1 + e^t} \right) - \ln \left( \frac{1}{1 + e^t} \right) = \\
\ln (e^t) - \ln (1 + e^t) - \big( \ln(1) - \ln(1 + e^t)\big) = \\
\ln(e^t) + \ln(1) = \ln(e^t) + 0 = t
\]</span></p>
</details>
</div>
<p>Функция, используемая для линеаризации связи между предиктором и зависимой переменной, называется <strong>функцией связи (linked function)</strong>. Функция logit-преобразоввания — одна из нескольких связывающих функций, применяемых для анализа бинарных переменных отклика.</p>
<p>Итак, summary от всего, что было выше:</p>
<ol style="list-style-type: decimal">
<li>От дискретной оценки событий (0 и 1) переходим к оценке вероятностей.</li>
<li>Связь вероятностей с предиктором описывается логистической кривой.</li>
<li>Если при помощи функции связи перейти от вероятностей к логитам, то связь будет описываться прямой линией.</li>
<li>Параметры линейной модели для такой прямой можно оценить с помощью регрессионного анализа.</li>
</ol>
</div>
</div>
<div id="binom_model" class="section level2 hasAnchor" number="17.6">
<h2><span class="header-section-number">17.6</span> Математическая модель<a href="binomial_regression.html#binom_model" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><span class="math display">\[
p_i = \frac{e^{\beta_0 + \beta_1 x_1 + \dots + \beta_p x_p}}{1 + e^{\beta_0 + \beta_1 x_1 + \dots + \beta_p x_p}}
\]</span></p>
<p>Функция связи (linked function):</p>
<p><span class="math display">\[
\ln \left( \frac{p_i}{1 - p_i} \right) = \eta_i \\
\eta_i = \beta_0 + \beta_1 x_{1i} + \dots + \beta_p x_{pi}
\]</span></p>
<p>Для перехода от логитов к вероятностям используется функция, обратная функции связи. В данном случае, логистическое преобразование:</p>
<p><span class="math display">\[
p_i = \frac{e^{\eta_i}}{1 + e^{\eta_i}}
\]</span></p>
</div>
<div id="binom_results" class="section level2 hasAnchor" number="17.7">
<h2><span class="header-section-number">17.7</span> Результаты логистической регрессии<a href="binomial_regression.html#binom_results" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>В общем таблица достаточно похожа на обычную линейную регрессию:</p>
<pre><code>## 
## Call:
## glm(formula = lvl ~ ., family = binomial(link = &quot;logit&quot;), data = managers)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -3.8626  -0.0897  -0.0800   0.0000   3.5607  
## 
## Coefficients:
##                      Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)         -22.08642    1.13159 -19.518  &lt; 2e-16 ***
## qualification         1.55224    0.14058  11.042  &lt; 2e-16 ***
## autonomy              0.18304    0.24017   0.762    0.446    
## subdiv_regulations   -0.08816    0.27523  -0.320    0.749    
## company_regulations   0.10685    0.21973   0.486    0.627    
## direct_juniors        8.86211    0.70679  12.539  &lt; 2e-16 ***
## func_juniors          2.98508    0.26324  11.340  &lt; 2e-16 ***
## income_influence      0.63992    0.16049   3.987 6.68e-05 ***
## error_cost           -0.04441    0.15745  -0.282    0.778    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 3626.58  on 3209  degrees of freedom
## Residual deviance:  640.79  on 3201  degrees of freedom
## AIC: 658.79
## 
## Number of Fisher Scoring iterations: 8</code></pre>
<p>Однако есть некоторые отличия.</p>
<p>Во-первых, нет <em>F</em>-статистики. Во-вторых, нет <span class="math inline">\(R^2\)</span>.</p>
<p>Это связано с тем, что алгоритм GLM не работает с дисперсией и суммой квадратов, так как задача подбора коэффициентов модели логистической регрессии не имеет аналитического решения, как было в случае линейной регрессии. Поэтому модель подбирается методом максимального правдоподобия.</p>
<div class="advanced">
<details>
<summary>
<em>Чё за метод такой?</em>
</summary>
<p><strong>Метод максимального правдоподобия</strong></p>
<p><strong>Правдоподобие (likelihood)</strong> — способ измерить соответствие имеющихся данных тому, что можно получить при определенных значениях параметров модели. Оно представляет собой произведение вероятностей получения каждой из точек данных:</p>
<p><span class="math display">\[
L(\theta | \mathrm{data}) = \prod_{i=1}^n f(\mathrm{data}|\theta),
\]</span></p>
<p>где <span class="math inline">\(f(\mathrm{data}|\theta)\)</span> — функция распределения с параметрами <span class="math inline">\(\theta\)</span>.</p>
<p>Параметры модели должны максимизировать значения правдоподобия, т.е.</p>
<p><span class="math display">\[
L(\theta | \mathrm{data}) \rightarrow \max
\]</span></p>
<p>Однако для упрощения вычислений используют логарифмы правдоподобий (loglikelihood) и максимизируют их</p>
<p><span class="math display">\[
\ln L(\theta | \mathrm{data}) \rightarrow \max
\]</span></p>
<p>Аналитически такие задачи решаются редко, чаще используются методы численной оптимизации — то есть компьютер просто перебирает разные варианты чисел и смотрит, какие лучше подходят. На рандомно, конечно, а с опорой на градиентный спуск, что бы это ни значило.</p>
</details>
</div>
</div>
<div id="binom_model_analysis" class="section level2 hasAnchor" number="17.8">
<h2><span class="header-section-number">17.8</span> Анализ модели<a href="binomial_regression.html#binom_model_analysis" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Итак, продолжим изучать аутпут логистической регрессии.</p>
<pre><code>## 
## Call:
## glm(formula = lvl ~ ., family = binomial(link = &quot;logit&quot;), data = managers)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -3.8626  -0.0897  -0.0800   0.0000   3.5607  
## 
## Coefficients:
##                      Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)         -22.08642    1.13159 -19.518  &lt; 2e-16 ***
## qualification         1.55224    0.14058  11.042  &lt; 2e-16 ***
## autonomy              0.18304    0.24017   0.762    0.446    
## subdiv_regulations   -0.08816    0.27523  -0.320    0.749    
## company_regulations   0.10685    0.21973   0.486    0.627    
## direct_juniors        8.86211    0.70679  12.539  &lt; 2e-16 ***
## func_juniors          2.98508    0.26324  11.340  &lt; 2e-16 ***
## income_influence      0.63992    0.16049   3.987 6.68e-05 ***
## error_cost           -0.04441    0.15745  -0.282    0.778    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 3626.58  on 3209  degrees of freedom
## Residual deviance:  640.79  on 3201  degrees of freedom
## AIC: 658.79
## 
## Number of Fisher Scoring iterations: 8</code></pre>
<p>Мы видим знакомую нам табличку с оценками коэффициентов. У каждого предиктора есть информация о значении коэффициента при нем (<code>Estimate</code>), значение стандартной ошибки, <em>z</em>-value и <em>p</em>-value, рассчитанный для последнего.</p>
<p>Судя по аутпуту, значимыми являются следующие предикторы: профессиональная квалификация, количество прямых и функциональных подчинённых и влияние на доход компании. Заметьте, что в этой модели значимых предикторов меньше, чем в модели обычной линейной регрессии. Но так ли это?</p>
<p>Внимательно посмотрим на эту табличку. Раньше у нас были значения t-статистики — теперь z-статистики. К чему это может приводить?</p>
<p>Чтобы ответить на этот вопрос, надо разобраться, что такое этот <em>z</em>-тест.</p>
<div id="z-test" class="section level3 hasAnchor" number="17.8.1">
<h3><span class="header-section-number">17.8.1</span> Тест Вальда<a href="binomial_regression.html#z-test" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<center>
<img src="pics/zvalue.png">
</center>
<p>Значение z-value является результатом подсчета <strong>теста Вальда</strong> и позволяет оценить значимость коэффициента модели. Расчет статистики похож на подсчет t-теста, только распределение данной статистики <em>ассимптотически</em> стремиться к нормальному (отсюда и <em>z</em>). Ассимптотика приводит к тому, что опеределение значимости коэффициентов на маленьких выборках будет неточным.</p>
<p><span class="math display">\[
H_0: \beta_k = 0 \\
H_1: \beta_k \neq 0 \\
\\
z = \frac{b_k - \beta_k}{SE_{b_k}} = \frac{b_k}{SE_{b_k}} \thicksim \mathcal{N}(0,\,1)
\]</span></p>
</div>
<div id="deviance_analysis" class="section level3 hasAnchor" number="17.8.2">
<h3><span class="header-section-number">17.8.2</span> Анализ девиансы и статистическая значимость модели<a href="binomial_regression.html#deviance_analysis" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Для получения более точных оценок необходимо поработать c логарифмами правдоподобий. Вообще логарифмы правдоподобий используются в GLM много для чего:</p>
<ul>
<li>для описания качества подгонки модели;</li>
<li>для тестирования значимости подобранной модели в целом;</li>
<li>для тестирования значимости отдельных предикторов;</li>
<li>для отбора моделей.</li>
</ul>
<p>Дла понимания механики анализа нам потребуется несколько полезных абстракций:</p>
<ul>
<li><strong>Насыщенная модель (saturated model)</strong> — каждое уникальное наблюдение (сочетание предикторов) описывается одним из <span class="math inline">\(n\)</span> параметров.</li>
</ul>
<p><span class="math display">\[
\ln L_{\mathrm{sat}} = 0 \\
\mathrm{df}_{\mathrm{sat}} = n - p_{\mathrm{sat}} = n - n = 0
\]</span></p>
<ul>
<li><strong>Нулевая модель (null model)</strong> — все наблюдения описываются одним параметром (средним значением).</li>
</ul>
<p><span class="math display">\[
\hat y_i = \beta_0 \\
\ln L_{\mathrm{null}} \neq 0 \rightarrow -\infty \\
\mathrm{df}_{\mathrm{null}} = n - p_{\mathrm{null}} = n - 1
\]</span></p>
<p>Наша <strong>реальная (предложенная) модель</strong>, которую мы подбираем, будет находится где-то между насыщенной и нулевой моделью (вернее, не сама модель, а значение логарифма её правдоподобия).</p>
<p><span class="math display">\[
\hat y_i = \beta_0 + \beta_1 x_{1i} + \dots + \beta_p x_{pi} \\
\ln L_{\mathrm{model}} \neq 0 \\
\mathrm{df}_\mathrm{model} = n - p_\mathrm{model}
\]</span></p>
<center>
<img src="pics/deviance.jpeg" width="50%">
</center>
<p><strong>Девианса</strong> является мерой различия правдоподобий двух моделей (оценка разницы логарифмов правдоподобий). [см. рисунок выше]</p>
<ul>
<li><strong>Остаточная девианса</strong></li>
</ul>
<p><span class="math display">\[
d_\mathrm{resid} = 2\big(\ln L_\mathrm{sat} - \ln L_\mathrm{model} \big) = -2 \ln(L_\mathrm{model})
\]</span></p>
<ul>
<li><strong>Нулевая девианса</strong></li>
</ul>
<p><span class="math display">\[
d_\mathrm{null} = 2 \big(\ln L_\mathrm{sat} - \ln L_\mathrm{null}\big) = -2 \ln(L_\mathrm{null})
\]</span></p>
<p>Сравнение нулевой и остаточной девианс позволяет судить о статистической значимости модели в целом. Такое сравнение проводится с помощью <strong>теста отношения правдоподобий (likelihood ratio test, LRT)</strong>.</p>
<p><span class="math display">\[
d_\mathrm{null} - d_\mathrm{resid} = -2 ( \ln L_\mathrm{null} - \ln L_\mathrm{model} ) = 2 (\ln L_\mathrm{model} - \ln L_\mathrm{null}) = 2 \ln \left( \frac{L_\mathrm{model}}{L_\mathrm{null}} \right) \\
\mathrm{LRT} = 2 \ln \left( \frac{L_\mathrm{M_1}}{L_\mathrm{M_2}} \right) = 2 (\ln L_\mathrm{M_1} - \ln L_\mathrm{M_2}),
\]</span>
где <span class="math inline">\(M_1,\, M_2\)</span> — вложенные модели (<span class="math inline">\(M_1\)</span> — более полная, <span class="math inline">\(M_2\)</span> — уменьшенная),
<span class="math inline">\(L_\mathrm{M_1}, \, L_\mathrm{M_2}\)</span> — правдоподобия.</p>
<p>Распределение разницы логарифмов правдоподобий аппроксиммируется распределением <span class="math inline">\(\chi^2\)</span> с числом степеней свободы <span class="math inline">\(\mathrm{df} = \mathrm{df}_\mathrm{M_2} - \mathrm{df}_\mathrm{M_1}\)</span>.</p>
<p>LRT для тестирования значимости модели в целом:</p>
<p><span class="math display">\[
\mathrm{LRT} = 2 \ln \left( \frac{L_\mathrm{model}}{L_\mathrm{null}} \right) = 2 (\ln L_\mathrm{model} - \ln L_{\mathrm{null}}) = d_\mathrm{null} - d_\mathrm{resid} \\
\mathrm{df} = p_\mathrm{model} - 1
\]</span></p>
<p>В конечном счете результаты анализа девиансы выглядят так:</p>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: lvl ~ 1
## Model 2: lvl ~ qualification + autonomy + subdiv_regulations + company_regulations + 
##     direct_juniors + func_juniors + income_influence + error_cost
##   Resid. Df Resid. Dev Df Deviance  Pr(&gt;Chi)    
## 1      3209     3626.6                          
## 2      3201      640.8  8   2985.8 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Как можно увидеть, наша модель получилась статистически значима. Ура!</p>
<p>Кроме статистических тестов для сравнения моделей можно использовать информационные критерии, как мы делали в случае обычной линейной регрессии.</p>
<p>AIC (Akaike information criterion):</p>
<pre><code>##            df       AIC
## model_null  1 3628.5775
## model       9  658.7949</code></pre>
<p>BIC (Bayesian information criterion):</p>
<pre><code>##            df       BIC
## model_null  1 3634.6516
## model       9  713.4611</code></pre>
</div>
</div>
<div id="coef_interpretation_binom" class="section level2 hasAnchor" number="17.9">
<h2><span class="header-section-number">17.9</span> Интерпретация коэффициентов модели<a href="binomial_regression.html#coef_interpretation_binom" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Чтобы было проще интерпретировать результаты, удалим из модели незначимые предикторы. Останется приемлемый аутпут:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="binomial_regression.html#cb9-1" aria-hidden="true" tabindex="-1"></a>model_new <span class="ot">&lt;-</span> <span class="fu">update</span>(model, .<span class="sc">~</span>. <span class="sc">-</span>autonomy <span class="sc">-</span>subdiv_regulations <span class="sc">-</span>company_regulations <span class="sc">-</span>error_cost)</span></code></pre></div>
<pre><code>## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred</code></pre>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="binomial_regression.html#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model_new)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = lvl ~ qualification + direct_juniors + func_juniors + 
##     income_influence, family = binomial(link = &quot;logit&quot;), data = managers)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -3.8408  -0.0852  -0.0852   0.0000   3.5391  
## 
## Coefficients:
##                  Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)      -22.0070     1.1112 -19.804  &lt; 2e-16 ***
## qualification      1.6056     0.1112  14.441  &lt; 2e-16 ***
## direct_juniors     8.8192     0.6459  13.653  &lt; 2e-16 ***
## func_juniors       3.0718     0.2423  12.680  &lt; 2e-16 ***
## income_influence   0.6440     0.1458   4.418 9.97e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 3626.58  on 3209  degrees of freedom
## Residual deviance:  641.78  on 3205  degrees of freedom
## AIC: 651.78
## 
## Number of Fisher Scoring iterations: 9</code></pre>
<p>Что значат эти непонятные коэффициенты при предикторах? В общих линейных моделях все ясно как белый день, а тут какая-то дичь…</p>
<p>Вспомним, что наша зависимая переменная — логарифм отношения шансов. От этого и будем толкаться.</p>
<p><span class="math display">\[
\ln \left(\frac{p_i}{1 - p_i}\right) = \eta_i \\
\eta_i = -22.0 + 1.6 \, \text{qualification}_i + 8.8 \, \text{direct_juniors}_{i} + 3.1 \, \text{func_juniors}_i + 0.6 \, \text{income_influence}_i
\]</span></p>
<p>Тогда,</p>
<ul>
<li><span class="math inline">\(b_0\)</span>, интерсепт, показывает <em>логарифм отношения шансов для случая, когда все остальные предикторы равны нулю</em> — в данном примере он сложноинетерпретабелен;</li>
<li><span class="math inline">\(b_j\)</span> показывает, <em>на сколько единиц изменяется логарифм отношения шансов</em> при изменении значения предиктора на единицу.</li>
</ul>
<p>Корректно, но непонятно… Чтобы разобраться лучше, немного потупим в алгебру.</p>
<div id="algebra_ln" class="section level3 hasAnchor" number="17.9.1">
<h3><span class="header-section-number">17.9.1</span> Немного алгебры для понимания сути коэффициентов<a href="binomial_regression.html#algebra_ln" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Пусть у нас есть модель с одним непрервным предиктором. Тогда она будет записываться так:</p>
<p><span class="math display">\[
\eta = b_0 + b_1 x
\]</span></p>
<p>В терминах логитов её можно записать следующим образом:</p>
<p><span class="math display">\[
\eta = \ln \left( \frac{p}{1 - p} \right) = \ln (\mathrm{odds})
\]</span></p>
<p>Как изменится предсказание модели при изменении предиктора на единицу?</p>
<p><span class="math display">\[
\eta_{x+1} - \eta_x = \ln (\mathrm{odds}_{x+1}) - \ln (\mathrm{odds}_{x}) =
\ln \left( \frac{\mathrm{odds}_{x+1}}{\mathrm{odds}_x} \right)
\]</span></p>
<p><span class="math display">\[
\eta_{x+1} - \eta_x = b_0 + b_1 (x + 1) - b_0 - b_1x = b_1
\]</span></p>
<p><span class="math display">\[
\ln \left( \frac{\mathrm{odds}_{x+1}}{\mathrm{odds}_{x}} \right) = b_1
\]</span></p>
<p><span class="math display">\[
\frac{\mathrm{odds}_{x+1}}{\mathrm{odds}_{x}} = e^{b_1}
\]</span></p>
<p>Таким образом, <span class="math inline">\(e^{b_1}\)</span> показывает, во сколько раз изменится отношение шансов при увеличении предиктора на единицу. Для дискретных предикторов <span class="math inline">\(e^{b_1}\)</span> покажет, во сколько раз различается отношение шансов для данного уровня предиктора по сравнению с базовым.</p>
<hr />
<center>
<img src="pics/geom_interpret.jpg">
</center>
<hr />
<p>Теперь мы можем трактовать полученные коэффициенты нормальным языком.</p>
<p><span class="math display">\[
\eta_i = -22.0 + 1.6 \, \text{qualification}_i + 8.8 \, \text{direct_juniors}_{i} + 3.1 \, \text{func_juniors}_i + 0.6 \, \text{income_influence}_i
\]</span></p>
<p>При увеличении оценки профессиональной квалификации на 1 отношение шансов принадлежать к уровню менеджеров увеличится в <span class="math inline">\(e^{1.6} = 4.95\)</span> раза. То есть работник, имеющий более высокую оценку профессиональной квалификации, имеет больше шансов быть менеджером.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ancova.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="final.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["SFDA.pdf", "SFDA.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
