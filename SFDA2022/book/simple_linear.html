<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>14 Простая линейная регрессия | Статистика для анализа данных</title>
  <meta name="description" content="Книжка для студентов бакалавриата «Психология» НИУ ВШЭ по курсу «Статистика для анализа данных»" />
  <meta name="generator" content="bookdown 0.29 and GitBook 2.6.7" />

  <meta property="og:title" content="14 Простая линейная регрессия | Статистика для анализа данных" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Книжка для студентов бакалавриата «Психология» НИУ ВШЭ по курсу «Статистика для анализа данных»" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="14 Простая линейная регрессия | Статистика для анализа данных" />
  
  <meta name="twitter:description" content="Книжка для студентов бакалавриата «Психология» НИУ ВШЭ по курсу «Статистика для анализа данных»" />
  

<meta name="author" content="Антон Ангельгардт" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="post_hoc.html"/>
<link rel="next" href="multiple_linear.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>




<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">СДАД 2022</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Врубаем тэхно для рабочего настроения</a></li>
<li class="part"><span><b>I Введение в статистику</b></span></li>
<li class="chapter" data-level="1" data-path="intro_stats.html"><a href="intro_stats.html"><i class="fa fa-check"></i><b>1</b> Введение в статистику</a>
<ul>
<li class="chapter" data-level="1.1" data-path="intro_stats.html"><a href="intro_stats.html#stat_terms"><i class="fa fa-check"></i><b>1.1</b> Исходные понятия статистики</a></li>
<li class="chapter" data-level="1.2" data-path="intro_stats.html"><a href="intro_stats.html#why_we_need_statistics"><i class="fa fa-check"></i><b>1.2</b> Зачем нужна статистика?</a></li>
<li class="chapter" data-level="1.3" data-path="intro_stats.html"><a href="intro_stats.html#representative_sample"><i class="fa fa-check"></i><b>1.3</b> Выборка должна быть репрезентативна</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="intro_stats.html"><a href="intro_stats.html#how_to_recruit_sample"><i class="fa fa-check"></i><b>1.3.1</b> Как набрать репрезентативную выборку</a></li>
<li class="chapter" data-level="1.3.2" data-path="intro_stats.html"><a href="intro_stats.html#способы-формирования-репрезентативной-выборки"><i class="fa fa-check"></i><b>1.3.2</b> Способы формирования репрезентативной выборки</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="scales_random_vars.html"><a href="scales_random_vars.html"><i class="fa fa-check"></i><b>2</b> Шкалы. Случайные величины. Распределения</a>
<ul>
<li class="chapter" data-level="2.1" data-path="scales_random_vars.html"><a href="scales_random_vars.html#intro_scales"><i class="fa fa-check"></i><b>2.1</b> Вспомним, что</a></li>
<li class="chapter" data-level="2.2" data-path="scales_random_vars.html"><a href="scales_random_vars.html#measuring"><i class="fa fa-check"></i><b>2.2</b> Измерение в социальных науках</a></li>
<li class="chapter" data-level="2.3" data-path="scales_random_vars.html"><a href="scales_random_vars.html#feaures_variables"><i class="fa fa-check"></i><b>2.3</b> Признаки и переменные</a></li>
<li class="chapter" data-level="2.4" data-path="scales_random_vars.html"><a href="scales_random_vars.html#scales"><i class="fa fa-check"></i><b>2.4</b> Шкалы</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="scales_random_vars.html"><a href="scales_random_vars.html#why_we_need_scales"><i class="fa fa-check"></i><b>2.4.1</b> Зачем нам знать виды шкал?</a></li>
<li class="chapter" data-level="2.4.2" data-path="scales_random_vars.html"><a href="scales_random_vars.html#types_of_scales"><i class="fa fa-check"></i><b>2.4.2</b> Типы шкал</a></li>
<li class="chapter" data-level="2.4.3" data-path="scales_random_vars.html"><a href="scales_random_vars.html#arrange_scales"><i class="fa fa-check"></i><b>2.4.3</b> Порядок шкал по мощности</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="scales_random_vars.html"><a href="scales_random_vars.html#random_valiables"><i class="fa fa-check"></i><b>2.5</b> Случайные величины</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="scales_random_vars.html"><a href="scales_random_vars.html#rand_exp"><i class="fa fa-check"></i><b>2.5.1</b> Случайный эксперимент. Исходы случайного эксперимента</a></li>
<li class="chapter" data-level="2.5.2" data-path="scales_random_vars.html"><a href="scales_random_vars.html#rand_var"><i class="fa fa-check"></i><b>2.5.2</b> Случайная величина</a></li>
<li class="chapter" data-level="2.5.3" data-path="scales_random_vars.html"><a href="scales_random_vars.html#дискретные-случайные-величины"><i class="fa fa-check"></i><b>2.5.3</b> Дискретные случайные величины</a></li>
<li class="chapter" data-level="2.5.4" data-path="scales_random_vars.html"><a href="scales_random_vars.html#непрерывные-случайные-величины"><i class="fa fa-check"></i><b>2.5.4</b> Непрерывные случайные величины</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Описательная статистика</b></span></li>
<li class="chapter" data-level="3" data-path="central_tendency.html"><a href="central_tendency.html"><i class="fa fa-check"></i><b>3</b> Меры центральной тенденции</a>
<ul>
<li class="chapter" data-level="3.1" data-path="central_tendency.html"><a href="central_tendency.html#types_of_statistics"><i class="fa fa-check"></i><b>3.1</b> Виды статистики</a></li>
<li class="chapter" data-level="3.2" data-path="central_tendency.html"><a href="central_tendency.html#central_tendency_measures"><i class="fa fa-check"></i><b>3.2</b> Меры центральной тенденции</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="central_tendency.html"><a href="central_tendency.html#mode"><i class="fa fa-check"></i><b>3.2.1</b> Мода</a></li>
<li class="chapter" data-level="3.2.2" data-path="central_tendency.html"><a href="central_tendency.html#медиана"><i class="fa fa-check"></i><b>3.2.2</b> Медиана</a></li>
<li class="chapter" data-level="3.2.3" data-path="central_tendency.html"><a href="central_tendency.html#среднее-арифметическое"><i class="fa fa-check"></i><b>3.2.3</b> Среднее арифметическое</a></li>
<li class="chapter" data-level="3.2.4" data-path="central_tendency.html"><a href="central_tendency.html#другие-средние"><i class="fa fa-check"></i><b>3.2.4</b> Другие средние</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="central_tendency.html"><a href="central_tendency.html#сравнение-мер-центральной-тенденции"><i class="fa fa-check"></i><b>3.3</b> Сравнение мер центральной тенденции</a></li>
<li class="chapter" data-level="3.4" data-path="central_tendency.html"><a href="central_tendency.html#mean_features"><i class="fa fa-check"></i><b>3.4</b> Свойства среднего арифметического</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="variation.html"><a href="variation.html"><i class="fa fa-check"></i><b>4</b> Меры разброса</a>
<ul>
<li class="chapter" data-level="4.1" data-path="variation.html"><a href="variation.html#why_we_need_variation"><i class="fa fa-check"></i><b>4.1</b> Зачем нужны меры разброса</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="variation.html"><a href="variation.html#key_features_of_data"><i class="fa fa-check"></i><b>4.1.1</b> Основные характеристики статистических данных</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="variation.html"><a href="variation.html#range"><i class="fa fa-check"></i><b>4.2</b> Минимум, максимум, размах</a></li>
<li class="chapter" data-level="4.3" data-path="variation.html"><a href="variation.html#quantiles"><i class="fa fa-check"></i><b>4.3</b> Квантили</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="variation.html"><a href="variation.html#quartiles"><i class="fa fa-check"></i><b>4.3.1</b> Квартили</a></li>
<li class="chapter" data-level="4.3.2" data-path="variation.html"><a href="variation.html#deciles"><i class="fa fa-check"></i><b>4.3.2</b> Децили</a></li>
<li class="chapter" data-level="4.3.3" data-path="variation.html"><a href="variation.html#percentiles"><i class="fa fa-check"></i><b>4.3.3</b> Перцентили</a></li>
<li class="chapter" data-level="4.3.4" data-path="variation.html"><a href="variation.html#iqr"><i class="fa fa-check"></i><b>4.3.4</b> Интерквартильный размах</a></li>
<li class="chapter" data-level="4.3.5" data-path="variation.html"><a href="variation.html#boxplot"><i class="fa fa-check"></i><b>4.3.5</b> Визуализация квартилей. Боксплот</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="variation.html"><a href="variation.html#var"><i class="fa fa-check"></i><b>4.4</b> Дисперсия</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="variation.html"><a href="variation.html#degrees_of_freedom"><i class="fa fa-check"></i><b>4.4.1</b> Степени свободы</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="variation.html"><a href="variation.html#sd"><i class="fa fa-check"></i><b>4.5</b> Стандартное отклонение</a></li>
<li class="chapter" data-level="4.6" data-path="variation.html"><a href="variation.html#variation_comparison"><i class="fa fa-check"></i><b>4.6</b> Сравнение мер разброса</a></li>
<li class="chapter" data-level="4.7" data-path="variation.html"><a href="variation.html#var_features"><i class="fa fa-check"></i><b>4.7</b> Свойства дисперсии и стандартного отклонения</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="normal_distribution.html"><a href="normal_distribution.html"><i class="fa fa-check"></i><b>5</b> Нормальное распределение</a>
<ul>
<li class="chapter" data-level="5.1" data-path="normal_distribution.html"><a href="normal_distribution.html#distributions"><i class="fa fa-check"></i><b>5.1</b> Распределение признаков в генеральной совокупности</a></li>
<li class="chapter" data-level="5.2" data-path="normal_distribution.html"><a href="normal_distribution.html#norm_dist"><i class="fa fa-check"></i><b>5.2</b> Нормальное распределение</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="normal_distribution.html"><a href="normal_distribution.html#norm_params"><i class="fa fa-check"></i><b>5.2.1</b> Параметры нормального распределения</a></li>
<li class="chapter" data-level="5.2.2" data-path="normal_distribution.html"><a href="normal_distribution.html#in_love_with_norm_dist"><i class="fa fa-check"></i><b>5.2.2</b> Почему все так любят нормальное распределение?</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="normal_distribution.html"><a href="normal_distribution.html#norm_shapes"><i class="fa fa-check"></i><b>5.3</b> Форма нормального распределения и параметры</a></li>
<li class="chapter" data-level="5.4" data-path="normal_distribution.html"><a href="normal_distribution.html#стандартные-отклонения-и-вероятности"><i class="fa fa-check"></i><b>5.4</b> Стандартные отклонения и вероятности</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="standardization.html"><a href="standardization.html"><i class="fa fa-check"></i><b>6</b> Стандартизация</a>
<ul>
<li class="chapter" data-level="6.1" data-path="standardization.html"><a href="standardization.html#стандартное-нормальное-распределение"><i class="fa fa-check"></i><b>6.1</b> Стандартное нормальное распределение</a></li>
<li class="chapter" data-level="6.2" data-path="standardization.html"><a href="standardization.html#стандартизация"><i class="fa fa-check"></i><b>6.2</b> Стандартизация</a></li>
<li class="chapter" data-level="6.3" data-path="standardization.html"><a href="standardization.html#интерпретация-z-значений"><i class="fa fa-check"></i><b>6.3</b> Интерпретация z-значений</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="clt_ci.html"><a href="clt_ci.html"><i class="fa fa-check"></i><b>7</b> Центральная предельная теорема и доверительные интервалы</a>
<ul>
<li class="chapter" data-level="7.1" data-path="clt_ci.html"><a href="clt_ci.html#interval_estim"><i class="fa fa-check"></i><b>7.1</b> Точечные и интервальные оценки</a></li>
<li class="chapter" data-level="7.2" data-path="clt_ci.html"><a href="clt_ci.html#clt"><i class="fa fa-check"></i><b>7.2</b> Центральная предельная теорема</a></li>
<li class="chapter" data-level="7.3" data-path="clt_ci.html"><a href="clt_ci.html#mean_se"><i class="fa fa-check"></i><b>7.3</b> Стандартная ошибка среднего</a></li>
<li class="chapter" data-level="7.4" data-path="clt_ci.html"><a href="clt_ci.html#mean_ci"><i class="fa fa-check"></i><b>7.4</b> Доверительные интервалы</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="clt_ci.html"><a href="clt_ci.html#ci_interpretation"><i class="fa fa-check"></i><b>7.4.1</b> Интерпретация границ доверительного интервала</a></li>
<li class="chapter" data-level="7.4.2" data-path="clt_ci.html"><a href="clt_ci.html#mean_ci_comp"><i class="fa fa-check"></i><b>7.4.2</b> Доверительный интервал и сравнение средних</a></li>
<li class="chapter" data-level="7.4.3" data-path="clt_ci.html"><a href="clt_ci.html#ci_se_sample_size"><i class="fa fa-check"></i><b>7.4.3</b> Связь доверительного интервала с разбросом и объемом выборки</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Статистика вывода и статметоды</b></span></li>
<li class="chapter" data-level="8" data-path="nhst.html"><a href="nhst.html"><i class="fa fa-check"></i><b>8</b> Тестирование статистических гипотех</a>
<ul>
<li class="chapter" data-level="8.1" data-path="nhst.html"><a href="nhst.html#базовые-понятия"><i class="fa fa-check"></i><b>8.1</b> Базовые понятия</a></li>
<li class="chapter" data-level="8.2" data-path="nhst.html"><a href="nhst.html#errors"><i class="fa fa-check"></i><b>8.2</b> Возможные результаты проверки гипотез</a></li>
<li class="chapter" data-level="8.3" data-path="nhst.html"><a href="nhst.html#stat_test_asymm"><i class="fa fa-check"></i><b>8.3</b> Асимметрия статистического вывода</a></li>
<li class="chapter" data-level="8.4" data-path="nhst.html"><a href="nhst.html#stat_test_algorithm"><i class="fa fa-check"></i><b>8.4</b> Алгоритм тестирования статистических гипотез</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="chisq.html"><a href="chisq.html"><i class="fa fa-check"></i><b>9</b> Анализ категориальных данных</a>
<ul>
<li class="chapter" data-level="9.1" data-path="chisq.html"><a href="chisq.html#crosstab"><i class="fa fa-check"></i><b>9.1</b> Таблица сопряженности</a></li>
<li class="chapter" data-level="9.2" data-path="chisq.html"><a href="chisq.html#theor_freq"><i class="fa fa-check"></i><b>9.2</b> Расчёт теоретических частот</a></li>
<li class="chapter" data-level="9.3" data-path="chisq.html"><a href="chisq.html#chisq_test"><i class="fa fa-check"></i><b>9.3</b> Критерий независимости Пирсона</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="chisq.html"><a href="chisq.html#распределение-chi2"><i class="fa fa-check"></i><b>9.3.1</b> Распределение <span class="math inline">\(\chi^2\)</span></a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="chisq.html"><a href="chisq.html#критерий-согласия-пирсона"><i class="fa fa-check"></i><b>9.4</b> Критерий согласия Пирсона</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="correlations.html"><a href="correlations.html"><i class="fa fa-check"></i><b>10</b> Корреляционный анализ</a>
<ul>
<li class="chapter" data-level="10.1" data-path="correlations.html"><a href="correlations.html#covariance"><i class="fa fa-check"></i><b>10.1</b> Ковариация</a></li>
<li class="chapter" data-level="10.2" data-path="correlations.html"><a href="correlations.html#correlation"><i class="fa fa-check"></i><b>10.2</b> Корреляция</a></li>
<li class="chapter" data-level="10.3" data-path="correlations.html"><a href="correlations.html#pearson_corr"><i class="fa fa-check"></i><b>10.3</b> Корреляция Пирсона</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="correlations.html"><a href="correlations.html#corr_test"><i class="fa fa-check"></i><b>10.3.1</b> Тестирование статистической значимости коэффициента корреляции</a></li>
<li class="chapter" data-level="10.3.2" data-path="correlations.html"><a href="correlations.html#cor_ci"><i class="fa fa-check"></i><b>10.3.2</b> Доверительный интервал для коэффициента корреляции</a></li>
<li class="chapter" data-level="10.3.3" data-path="correlations.html"><a href="correlations.html#effect_size_cor"><i class="fa fa-check"></i><b>10.3.3</b> Размер эффекта для коэффициента корреляции</a></li>
<li class="chapter" data-level="10.3.4" data-path="correlations.html"><a href="correlations.html#power_corr"><i class="fa fa-check"></i><b>10.3.4</b> Расчет объема выборки для корреляционного анализа</a></li>
<li class="chapter" data-level="10.3.5" data-path="correlations.html"><a href="correlations.html#cor_vis"><i class="fa fa-check"></i><b>10.3.5</b> Визуализация корреляции</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="correlations.html"><a href="correlations.html#corr_coefs"><i class="fa fa-check"></i><b>10.4</b> Коэффициенты корреляции для разных шкал</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="correlations.html"><a href="correlations.html#param_vs_nonparam"><i class="fa fa-check"></i><b>10.4.1</b> Параметрические и непараметрические критерии</a></li>
<li class="chapter" data-level="10.4.2" data-path="correlations.html"><a href="correlations.html#nonparam_corr"><i class="fa fa-check"></i><b>10.4.2</b> Непараметрические коэффициенты корреляции</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="correlations.html"><a href="correlations.html#other_cor"><i class="fa fa-check"></i><b>10.5</b> Другие корреляции</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="correlations.html"><a href="correlations.html#phi_coef"><i class="fa fa-check"></i><b>10.5.1</b> <span class="math inline">\(\phi\)</span>-коэффициент</a></li>
<li class="chapter" data-level="10.5.2" data-path="correlations.html"><a href="correlations.html#biserial_cor"><i class="fa fa-check"></i><b>10.5.2</b> Бисериальный коэффициент корреляции</a></li>
<li class="chapter" data-level="10.5.3" data-path="correlations.html"><a href="correlations.html#rank_biserial_cor"><i class="fa fa-check"></i><b>10.5.3</b> Рангово-бисериальный коэффициент корреляции</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="oneway-anova.html"><a href="oneway-anova.html"><i class="fa fa-check"></i><b>11</b> Общие линейные модели. Однофакторный дисперсионный анализ</a>
<ul>
<li class="chapter" data-level="11.1" data-path="oneway-anova.html"><a href="oneway-anova.html#experiment"><i class="fa fa-check"></i><b>11.1</b> Э-э-эксперимент</a></li>
<li class="chapter" data-level="11.2" data-path="oneway-anova.html"><a href="oneway-anova.html#var_struct"><i class="fa fa-check"></i><b>11.2</b> Структура изменчивости данных</a></li>
<li class="chapter" data-level="11.3" data-path="oneway-anova.html"><a href="oneway-anova.html#why_anova"><i class="fa fa-check"></i><b>11.3</b> Зачем нужен дисперсионный анализ?</a></li>
<li class="chapter" data-level="11.4" data-path="oneway-anova.html"><a href="oneway-anova.html#f_test"><i class="fa fa-check"></i><b>11.4</b> Тестирование значимости фактора</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="oneway-anova.html"><a href="oneway-anova.html#распределение-фишера"><i class="fa fa-check"></i><b>11.4.1</b> Распределение Фишера</a></li>
<li class="chapter" data-level="11.4.2" data-path="oneway-anova.html"><a href="oneway-anova.html#anova_results"><i class="fa fa-check"></i><b>11.4.2</b> Представление результатов дисперсионного анализа</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="oneway-anova.html"><a href="oneway-anova.html#eta_sq"><i class="fa fa-check"></i><b>11.5</b> Размер эффекта в дисперсионном анализе</a></li>
<li class="chapter" data-level="11.6" data-path="oneway-anova.html"><a href="oneway-anova.html#anova_vis"><i class="fa fa-check"></i><b>11.6</b> Визуализация результатов дисперсионного анализа</a></li>
<li class="chapter" data-level="11.7" data-path="oneway-anova.html"><a href="oneway-anova.html#anova_require"><i class="fa fa-check"></i><b>11.7</b> Условия применения дисперсионного анализа</a>
<ul>
<li class="chapter" data-level="11.7.1" data-path="oneway-anova.html"><a href="oneway-anova.html#homogenity"><i class="fa fa-check"></i><b>11.7.1</b> Гомогенность дисперсий</a></li>
</ul></li>
<li class="chapter" data-level="11.8" data-path="oneway-anova.html"><a href="oneway-anova.html#anova_effects"><i class="fa fa-check"></i><b>11.8</b> Виды эффектов в дисперсионном анализе</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="twoway-anova.html"><a href="twoway-anova.html"><i class="fa fa-check"></i><b>12</b> Многофакторный дисперионный анализ</a>
<ul>
<li class="chapter" data-level="12.1" data-path="twoway-anova.html"><a href="twoway-anova.html#experiment2"><i class="fa fa-check"></i><b>12.1</b> Усложняем э-э-эксперимент</a></li>
<li class="chapter" data-level="12.2" data-path="twoway-anova.html"><a href="twoway-anova.html#factor_interaction"><i class="fa fa-check"></i><b>12.2</b> Взаимодействие факторов</a></li>
<li class="chapter" data-level="12.3" data-path="twoway-anova.html"><a href="twoway-anova.html#twoway_results"><i class="fa fa-check"></i><b>12.3</b> Результаты многофакторного дисперсионного анализа и тестирование значимости факторов и взаимодействий</a></li>
<li class="chapter" data-level="12.4" data-path="twoway-anova.html"><a href="twoway-anova.html#rmanova_require"><i class="fa fa-check"></i><b>12.4</b> Условия применения дисперсионного анализа с повторными измерениям</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="twoway-anova.html"><a href="twoway-anova.html#sphericity"><i class="fa fa-check"></i><b>12.4.1</b> Сферичность</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="twoway-anova.html"><a href="twoway-anova.html#type_of_sums"><i class="fa fa-check"></i><b>12.5</b> Типы сумм квадратов</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="post_hoc.html"><a href="post_hoc.html"><i class="fa fa-check"></i><b>13</b> Post hoc тесты. Критерий Стьюдента. Проблема множественных сравнений</a>
<ul>
<li class="chapter" data-level="13.1" data-path="post_hoc.html"><a href="post_hoc.html#pairwise_comp"><i class="fa fa-check"></i><b>13.1</b> Попарные сравнения</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="post_hoc.html"><a href="post_hoc.html#multiple_comp"><i class="fa fa-check"></i><b>13.1.1</b> Проблема множественных сравнений</a></li>
<li class="chapter" data-level="13.1.2" data-path="post_hoc.html"><a href="post_hoc.html#p-adj"><i class="fa fa-check"></i><b>13.1.2</b> Корректировка уровня значимости</a></li>
<li class="chapter" data-level="13.1.3" data-path="post_hoc.html"><a href="post_hoc.html#anova_vs_mult_comp"><i class="fa fa-check"></i><b>13.1.3</b> Дисперсионный анализ и проблема множественных сравнений</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="post_hoc.html"><a href="post_hoc.html#t-test"><i class="fa fa-check"></i><b>13.2</b> Двухвыборочный t-тест</a></li>
<li class="chapter" data-level="13.3" data-path="post_hoc.html"><a href="post_hoc.html#paired-t-test"><i class="fa fa-check"></i><b>13.3</b> Парный t-тест</a></li>
<li class="chapter" data-level="13.4" data-path="post_hoc.html"><a href="post_hoc.html#post_hoc_test"><i class="fa fa-check"></i><b>13.4</b> Че за post hoc?</a></li>
<li class="chapter" data-level="13.5" data-path="post_hoc.html"><a href="post_hoc.html#t-test-per-se"><i class="fa fa-check"></i><b>13.5</b> t-тест — сильный и независимый</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="simple_linear.html"><a href="simple_linear.html"><i class="fa fa-check"></i><b>14</b> Простая линейная регрессия</a>
<ul>
<li class="chapter" data-level="14.1" data-path="simple_linear.html"><a href="simple_linear.html#simple_reg_formalization"><i class="fa fa-check"></i><b>14.1</b> Формализация модели</a></li>
<li class="chapter" data-level="14.2" data-path="simple_linear.html"><a href="simple_linear.html#simple_reg_indentification"><i class="fa fa-check"></i><b>14.2</b> Идентификация модели</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="simple_linear.html"><a href="simple_linear.html#least-squares"><i class="fa fa-check"></i><b>14.2.1</b> Метод наименьших квадратов</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="simple_linear.html"><a href="simple_linear.html#simple_reg_quality"><i class="fa fa-check"></i><b>14.3</b> Тестирование качества модели</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="simple_linear.html"><a href="simple_linear.html#r-squared"><i class="fa fa-check"></i><b>14.3.1</b> Коэффициент детерминации</a></li>
<li class="chapter" data-level="14.3.2" data-path="simple_linear.html"><a href="simple_linear.html#simple_reg_significance"><i class="fa fa-check"></i><b>14.3.2</b> Статистическая значимость модели</a></li>
<li class="chapter" data-level="14.3.3" data-path="simple_linear.html"><a href="simple_linear.html#simple_reg_t_test"><i class="fa fa-check"></i><b>14.3.3</b> Статистическая значимость отдельных предикторов</a></li>
<li class="chapter" data-level="14.3.4" data-path="simple_linear.html"><a href="simple_linear.html#simple_regression_results"><i class="fa fa-check"></i><b>14.3.4</b> Результаты регрессионного анализа</a></li>
<li class="chapter" data-level="14.3.5" data-path="simple_linear.html"><a href="simple_linear.html#slope_interpretation_simple_linear"><i class="fa fa-check"></i><b>14.3.5</b> Интерпретация коэффициента при предикторе</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="simple_linear.html"><a href="simple_linear.html#simple_reg_diagnostics"><i class="fa fa-check"></i><b>14.4</b> Диагностика модели</a></li>
<li class="chapter" data-level="14.5" data-path="simple_linear.html"><a href="simple_linear.html#corr_vs_lm"><i class="fa fa-check"></i><b>14.5</b> Корреляция vs регрессия</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="multiple_linear.html"><a href="multiple_linear.html"><i class="fa fa-check"></i><b>15</b> Множественная линейная регрессия</a>
<ul>
<li class="chapter" data-level="15.1" data-path="multiple_linear.html"><a href="multiple_linear.html#several_predictors"><i class="fa fa-check"></i><b>15.1</b> Связи между несколькими переменными</a></li>
<li class="chapter" data-level="15.2" data-path="multiple_linear.html"><a href="multiple_linear.html#multiple_linear_quanti"><i class="fa fa-check"></i><b>15.2</b> Множественная линейная регрессия с количественными предикторами</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="multiple_linear.html"><a href="multiple_linear.html#multicollinearity"><i class="fa fa-check"></i><b>15.2.1</b> Проблема мультиколлинеарности</a></li>
<li class="chapter" data-level="15.2.2" data-path="multiple_linear.html"><a href="multiple_linear.html#multiple_linear_results"><i class="fa fa-check"></i><b>15.2.2</b> Результаты множественной линейной регрессии</a></li>
<li class="chapter" data-level="15.2.3" data-path="multiple_linear.html"><a href="multiple_linear.html#r_squared_adjusted"><i class="fa fa-check"></i><b>15.2.3</b> Скорректированный <span class="math inline">\(R^2\)</span></a></li>
<li class="chapter" data-level="15.2.4" data-path="multiple_linear.html"><a href="multiple_linear.html#vif"><i class="fa fa-check"></i><b>15.2.4</b> Исследование мультиколлинеарности</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="multiple_linear.html"><a href="multiple_linear.html#multiple_linear_quali_quanti"><i class="fa fa-check"></i><b>15.3</b> Множественная линейная регрессия с количественными и категориальными предикторами</a>
<ul>
<li class="chapter" data-level="15.3.1" data-path="multiple_linear.html"><a href="multiple_linear.html#multiple_linear_quali_quanti_model"><i class="fa fa-check"></i><b>15.3.1</b> Математическая модель</a></li>
<li class="chapter" data-level="15.3.2" data-path="multiple_linear.html"><a href="multiple_linear.html#multiple_linear_quali_quanti_results"><i class="fa fa-check"></i><b>15.3.2</b> Результаты множественной линейной регрессии с количественными и категориальными предикторами</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="multiple_linear.html"><a href="multiple_linear.html#predictor_interaction"><i class="fa fa-check"></i><b>15.4</b> Модели со взаимодействием предикторов</a></li>
<li class="chapter" data-level="15.5" data-path="multiple_linear.html"><a href="multiple_linear.html#regression_anova"><i class="fa fa-check"></i><b>15.5</b> Линейная регрессия только с категориальными предикторами</a>
<ul>
<li class="chapter" data-level="15.5.1" data-path="multiple_linear.html"><a href="multiple_linear.html#regression_oneway_anova"><i class="fa fa-check"></i><b>15.5.1</b> Простая линейная регрессия только с категориальными предикторами</a></li>
<li class="chapter" data-level="15.5.2" data-path="multiple_linear.html"><a href="multiple_linear.html#regression_twoway_anova"><i class="fa fa-check"></i><b>15.5.2</b> Множественная линейная регрессия только с категориальными предикторами</a></li>
</ul></li>
<li class="chapter" data-level="15.6" data-path="multiple_linear.html"><a href="multiple_linear.html#model_comparison"><i class="fa fa-check"></i><b>15.6</b> Сравнение моделей</a>
<ul>
<li class="chapter" data-level="15.6.1" data-path="multiple_linear.html"><a href="multiple_linear.html#r_squared_comparison"><i class="fa fa-check"></i><b>15.6.1</b> Коэффициент детерминации</a></li>
<li class="chapter" data-level="15.6.2" data-path="multiple_linear.html"><a href="multiple_linear.html#F_partial"><i class="fa fa-check"></i><b>15.6.2</b> Частный F-критерий</a></li>
<li class="chapter" data-level="15.6.3" data-path="multiple_linear.html"><a href="multiple_linear.html#mse_rmse_mae"><i class="fa fa-check"></i><b>15.6.3</b> Ошибки моделей</a></li>
<li class="chapter" data-level="15.6.4" data-path="multiple_linear.html"><a href="multiple_linear.html#bic_aic"><i class="fa fa-check"></i><b>15.6.4</b> Информационные критерии</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="ancova.html"><a href="ancova.html"><i class="fa fa-check"></i><b>16</b> Ковариационный анализ</a></li>
<li class="chapter" data-level="17" data-path="binomial_regression.html"><a href="binomial_regression.html"><i class="fa fa-check"></i><b>17</b> Логистическая регрессия</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Статистика для анализа данных</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="simple_linear" class="section level1 hasAnchor" number="14">
<h1><span class="header-section-number">14</span> Простая линейная регрессия<a href="simple_linear.html#simple_linear" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Ненадолго откатимся обратно к корреляции. Она позволяет тестировать гипотезы о связях между количественными переменными. Однако кроме проверки наличия или отсутствия связей между переменными, нас ещё интересует, как бы мы могли управлять одними переменными с помощью других. Для этого необходимо построение некоторой модели.</p>
<p>Когда мы строили диаграммы рассеяния, мы добавляли на них <em>линию тренда</em>, которая отражала линейную составляющую связи между визуализируемыми переменными.</p>
<center>
<img src="pics/cov4.jpeg">
</center>
<p>Эта линия и есть интересующая нас модель. Визуально мы такую линию проведём очень легко, а вот как мы нам получить её математическое выражение?</p>
<div id="simple_reg_formalization" class="section level2 hasAnchor" number="14.1">
<h2><span class="header-section-number">14.1</span> Формализация модели<a href="simple_linear.html#simple_reg_formalization" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Первое, что нужно вспомнить — это общее уравнение прямой. Оно выглядит так:</p>
<p><span class="math display">\[
y = kx + b,
\]</span></p>
<p>где <span class="math inline">\(k\)</span> — угловой коэффициент (slope), задающий угол наклона прямой к оси <span class="math inline">\(x\)</span>, а <span class="math inline">\(b\)</span> — свободный член (intercept), который обозначает ординату точки пересечения прямой с осью <span class="math inline">\(y\)</span>.</p>
<p>Итого, чтобы получить уравнение прямой, нам надо знать два этих числа. Что у нас есть, для этого есть? У нас есть наши наблюдения — то есть <span class="math inline">\(x\)</span> и <span class="math inline">\(y\)</span>.</p>
<p>Мы привыкли к тому, что <span class="math inline">\(x\)</span> и <span class="math inline">\(y\)</span> являются неизвестными, но теперь, когда мы ищем уравнение прямой на основе имеющихся измерений, ситуация изменяется.</p>
<p>Запишем уравнение, используя общепринятие обозначения.</p>
<p><span class="math display">\[
y = b_0 + b_1 x
\]</span></p>
<p>Уравнение отражает зависимость между переменными <span class="math inline">\(x\)</span> и <span class="math inline">\(y\)</span>, значения которых нам известны, так как у нас есть результаты измерений, а вот неизвестными теперь являются <span class="math inline">\(b_0\)</span> и <span class="math inline">\(b_1\)</span>.</p>
<p>В терминах статистической модели:</p>
<ul>
<li>переменная <span class="math inline">\(y\)</span> называется <em>зависимая</em>, <em>предсказываемая</em>, <em>целевая переменная</em> или <em>регрессант</em></li>
<li>переменная <span class="math inline">\(x\)</span> носит названия <em>независимая переменная</em>, <em>предиктор</em> или <em>регрессор</em></li>
<li><span class="math inline">\(b_0\)</span> и <span class="math inline">\(b_1\)</span> называются <em>коэффициентами</em> или <em>параметрами</em> модели.</li>
</ul>
<p><strong>Важно!</strong> Несмотря на использование терминов <em>зависимая</em> и <em>независимая</em> переменные, необходимо чётко понимать, что сам регрессионный анализ, как и корреляционный, ничего нам не говорит о причинности. Мы выражаем <span class="math inline">\(y\)</span> через <span class="math inline">\(x\)</span>, но точно так же можем выразить и <span class="math inline">\(x\)</span> через <span class="math inline">\(y\)</span> — и модель будет подобрана, так как нет никаких математических ограничений. Поэтому если мы хотим сделать по результатам регрессионного анализа вывод о причинно-следственной связи между явлениями, нам необходимо либо серьёзное теоретическое обоснование нашего вывода — почему мы выбрали в качестве зависимой и независимой переменных именно эти? — либо использование экспериментельного дизайна исследования, где мы обосновываем причинно-следственный характер связи именно через дизайн эксперимента.</p>
</div>
<div id="simple_reg_indentification" class="section level2 hasAnchor" number="14.2">
<h2><span class="header-section-number">14.2</span> Идентификация модели<a href="simple_linear.html#simple_reg_indentification" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Идентификация модели сводится к нахождению коэффициентов <span class="math inline">\(b_0\)</span> и <span class="math inline">\(b_1\)</span>. Мы хотим провести такую прямую, которая наилучшим образом будет описывать имеющуюся в данных закономерность, поэтому необходимо найти критерий, по которому мы будем определять «хорошесть» нашей прямой.</p>
<p>Графически мы делаем вот что: проводим прямую через облако точек. Очевидно, что красная прямая описывает закономерность совсем плохо, зелёная — чуть получше, а синяя — то, что нам нужно.</p>
<center>
<img src="pics/trend_lines.jpeg">
</center>
<p>Из картинки также очевидно, что даже синяя прамая не описывает наши данные максимально точно — не все точки попали на прямую. Ясно, что такой прямой мы провести и не сможем — точек же целое облако. Поэтому любая построенная нами модель будет содержать ошибку — вновь по причине вариативности и неопределенности данных. Таким образом, модель, «хорошесть» которой мы пытаемся определить выглядит так:</p>
<p><span class="math display">\[
y_i = b_0 + b_1 x_i + e_i
\]</span></p>
<p>А графически ошибки будут тут:</p>
<center>
<img src="pics/errors_lm.jpeg">
</center>
<p>Уравнение же нашей модели вот такое:</p>
<p><span class="math display">\[
\hat y = b_0 + b_1 x
\]</span></p>
<p>Игрек в шляпке показывает, что это <em>моделируемое</em> значение нашей целевой переменной, и оно отличается от того, которое есть в данных.</p>
<p>Собственно, задача идентификации модели — <em>минимизировать ошибку модели</em>, подбирая её параметры.</p>
<p><span class="math display">\[
Q_{res} = \sum_{i=1}^n e_i^2 = \sum_{i=1}^n \big(y_i - (b_0 + b_1x_i) \big)^2 = \sum_{i=1}^n (y_i - \hat y_i)^2 \rightarrow \underset{b_0, b_1}{\min}
\]</span></p>
<p>Ошибки модели <span class="math inline">\(e_i\)</span> также называются <strong>остатки (residuals)</strong>, то есть то, что модель не смогла объяснить. Обозначенное выше условие минимизации ошибки лежит в основе <strong>метода наименьших квадратов</strong>.</p>
<div id="least-squares" class="section level3 hasAnchor" number="14.2.1">
<h3><span class="header-section-number">14.2.1</span> Метод наименьших квадратов<a href="simple_linear.html#least-squares" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="advanced">
<details>
<summary>
<em>Осторожно! Очень математично!</em>
</summary>
<p>Если внимательно посмотреть на условие минимизации ошибки модели, то можно увидеть, что оно представляет собой функцию двух аргументов:</p>
<p><span class="math display">\[
f(b_0, b_1) = \sum_{i=1}^n (y_i - b_0 - b_1 x_i)^2
\]</span></p>
<p>Это квадратичная функция, и чтобы нам дальше удобнее было с ней работать, раскроем скобки:</p>
<p><span class="math display">\[
f(b_0, b_1) = \sum_{i=1}^n (y_i - b_0 - b_1 x_i)(y_i - b_0 - b_1 x_i) \\
f(b_0, b_1) = \sum_{i=1}^n (y_i^2 - 2 x_i y_i b_1 - 2 y_i b_0 + x_i^2 b_1^2 + b_0^2 + 2 x_i b_1 b_0)
\]</span></p>
<p>Чтобы определить, при каких значения <span class="math inline">\(b_0\)</span> и <span class="math inline">\(b_1\)</span> функция будет принимать минимальное значение, нужно взять две <a href="https://ru.wikipedia.org/wiki/%D0%A7%D0%B0%D1%81%D1%82%D0%BD%D0%B0%D1%8F_%D0%BF%D1%80%D0%BE%D0%B8%D0%B7%D0%B2%D0%BE%D0%B4%D0%BD%D0%B0%D1%8F">частные производные</a> по <span class="math inline">\(b_0\)</span> и <span class="math inline">\(b_1\)</span> и приравнять их в нулю.</p>
<p>Берём частные производные:</p>
<p><span class="math display">\[
\frac{f(b_0, b_1)}{\partial b_0} = \sum_{i=1}^n (-2 y_i + 2 b_0 + 2 x_i b_1) = -2 \sum_{i=1}^n \big(y_i - (b_0 + b_1 x_i) \big) \\
\frac{f(b_0, b_1)}{\partial b_1} = \sum_{i=1}^n (-2 x_i y_i + 2 x_i^2 b_1 + 2 x_i b_0) = -2 \sum_{i=1}^n \big(y_i - (b_0+ b_1 x_i) \big) x_i
\]</span></p>
<p>Приравниваем производные к нулю и решаем систему уравнений:</p>
<p><span class="math display">\[
\cases {
-2 \sum_{i=1}^n \big(y_i - (b_0 + b_1 x_i) \big) = 0, \\
-2 \sum_{i=1}^n \big(y_i - (b_0+ b_1 x_i) \big) x_i = 0;
}
\]</span>
<span class="math display">\[
\cases {
b_1 \sum_{i=1}^n x_i + \sum_{i=1}^n b_0 = \sum_{i=1}^n y_i, \\
b_1 \sum_{i=1}^n x_i^2 + b_0 \sum_{i=1}^n x_i = \sum_{i=1}^n x_i y_i;
}
\]</span>
<span class="math display">\[
\cases {
b_1 \sum_{i=1}^n x_i + n b_0 = \sum_{i=1}^n y_i, \\
b_1 \sum_{i=1}^n x_i^2 + b_0 \sum_{i=1}^n x_i = \sum_{i=1}^n x_i y_i;
}
\]</span></p>
<p><span class="math display">\[
\cases {
b_0 = \dfrac{\sum_{i=1}^n y_i}{n} - b_1 \dfrac{\sum_{i=1}^n x_i}{n} = \bar y - b_1 \bar x \\
b_1 = \dfrac{n \sum_{i=1}^n x_i y_i - \sum_{i=1}^n x_i \sum_{i=1}^n y_i}{n \sum_{i=1}^n x_i^2 - \big( \sum_{i=1}^n x_i \big)^2} = \dfrac{\overline {xy} - \bar x \cdot \bar y}{\sigma^2_x}
}
\]</span></p>
</details>
</div>
<p>В сухом остатке из метода наименьших квадратов на надо вынести вот что:</p>
<ul>
<li><em>задача индентификации модели линейной регрессии имеет аналитическое решение</em> — то есть мы можем подобрать коэффициенты модели, опираясь только на имеющиеся данные</li>
<li>и оно вот такое</li>
</ul>
<p><span class="math display">\[
\cases {
b_0 = \bar y - b_1 \bar x \\
b_1 = \dfrac{\overline {xy} - \bar x \cdot \bar y}{\sigma^2_x} = \dfrac{\sum (x_i - \bar x) (y_i - \bar y)}{\sum (x_i - \bar x)^2}
}
\]</span></p>
<p>Это, безусловно, радостно и приятно.</p>
<div class="advanced">
<details>
<summary>
<em>А если вы умеете в матрицы, то всё ещё проще</em>
</summary>
<p>Аналитическое вычисление коэффициентов выглядит громоздко и трудоёмко — хотелось бы как-то попроще. Нам на помощь приходят матрицы!</p>
<p>Имеющуюся у нас модель мы можем переписать в следующем виде:</p>
<p><span class="math display">\[
\boldsymbol{y}= \boldsymbol{X}\boldsymbol{b}+ \boldsymbol{e},
\]</span>
где <span class="math inline">\(\boldsymbol{y}\)</span> — вектор нашей зависимой переменной, <span class="math inline">\(\boldsymbol{X}\)</span> — матрица независимых переменных, <span class="math inline">\(\boldsymbol{b}\)</span> — вектор коэффициентов модели, <span class="math inline">\(\boldsymbol{e}\)</span> — вектор ошибок (остатков) модели.</p>
<p>Может возникнуть резонный вопрос: «почему <span class="math inline">\(\boldsymbol{X}\)</span> матрица, ведь у нас только одна независимая переменная?». Так как вектор коэффициентов модели <span class="math inline">\(\boldsymbol{b}\)</span> содержит два элемента <span class="math inline">\((b_0, b_1)^\mathrm{T}\)</span>, то для удобства вычислений к вектору значений предиктора <span class="math inline">\(x\)</span> дообавляют вектор, состоящий из единиц, который будет отвечать за интерсепт нашей модел — в результате получается матрица <span class="math inline">\(\boldsymbol{X}\)</span>, которая имеет следующий вид:</p>
<p><span class="math display">\[
\boldsymbol{X}=
\begin{pmatrix}
1 &amp; x_{11} \\
1 &amp; x_{21} \\
1 &amp; x_{31} \\
\vdots &amp; \vdots \\
1 &amp; x_{n1}
\end{pmatrix}
\]</span></p>
<p>При умножении вектора <span class="math inline">\(\boldsymbol{b}= (b_0, b_1)^\mathrm{T}\)</span> на матрицу <span class="math inline">\(\boldsymbol{X}\)</span> как раз будут получатся выражения типа <span class="math inline">\(b_0 \cdot 1 + b_1 x_{i1}\)</span>, а это то, что нам надо.</p>
<p>Опуская детали, сразу укажем матричное решение для коэффициентов модели:</p>
<p><span class="math display">\[
\boldsymbol{b}= (\boldsymbol{X}^\mathrm{T}\boldsymbol{X})^{-1}\boldsymbol{X}^\mathrm{T}\boldsymbol{y}
\]</span></p>
<p>Выглядит проще, не так ли?</p>
<blockquote>
<p>Нужно заметить ещё один важный момент: в ходе вычисления коэффициентов мы берём обратную матрицу от матрицы <span class="math inline">\(X^\mathrm{T}X\)</span>. Этот факт нам будет полезен в следующем разделе.</p>
</blockquote>
</details>
</div>
</div>
</div>
<div id="simple_reg_quality" class="section level2 hasAnchor" number="14.3">
<h2><span class="header-section-number">14.3</span> Тестирование качества модели<a href="simple_linear.html#simple_reg_quality" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Супер! Мы построили модель! Теперь надо понять, насколько она хороша для наших данных. Но перед этим нам надо сделать шаг назад и прояснить ряд моментов, на которые мы имплицитно опираемся, но пока ещё не проговорили.</p>
<p>Мы помним, что работая с выборкой, мы хотим получить информацию о генеральной совокупности. Строя модель, мы предполагаем, что в генеральной совокупности есть связь, которая описывается следующим уравнением:</p>
<p><span class="math display">\[
y_i = \beta_0 + \beta_1 x_i + \varepsilon_i
\]</span></p>
<p>Таким образом, построив модель, мы получили оценки генеральных параметров:</p>
<p><span class="math display">\[
b_0 = \hat \beta_0, \quad b_1 = \hat \beta_1, \quad e_i = \hat \varepsilon_i
\]</span></p>
<p>Кроме того, при построении модели мы также исходили из нескольких предположений.</p>
<ul>
<li>Во-первых, мы считали, что связь между предикторами и зависимой переменной <strong>линейная</strong>.</li>
<li>Во-вторых, мы предположили, что наша модель полностью улавливает тренд закономерности, то остатки (ошибки) модели случайны. Их <strong>среднее равно нулю</strong>: <span class="math inline">\(\bar \varepsilon = 0\)</span>,</li>
<li>а также <strong>остатки модели не коррелируют между собой</strong>: <span class="math inline">\(\text{cor} (\underset{i \neq j}{\varepsilon_i \varepsilon_j}) = 0\)</span>.</li>
<li>Ну, а раз остатки заключают в себе случайный компонент модели, то они должны быть <strong>распределены нормально</strong> <span class="math inline">\(\varepsilon \thicksim \mathcal{N}(0, \sigma^2)\)</span>,</li>
<li>причём их <strong>дисперсия должна быть одинакова при любых значениях предиктора</strong> <span class="math inline">\(\sigma_i^2 = \sigma^2 = \mathrm{const}\)</span>.</li>
</ul>
<p>Так-с, ну, теперь можно приступать с анализу модели.</p>
<div id="r-squared" class="section level3 hasAnchor" number="14.3.1">
<h3><span class="header-section-number">14.3.1</span> Коэффициент детерминации<a href="simple_linear.html#r-squared" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Первое, что хочется понять — насколько наша модель информативна. Иначе говоря, сколько дисперсии наших данных она смогла объяснить. На практике работают не с дисперсией, а с <em>суммой квадратов</em>, что почти то же самое — это мы уже видели в дисперсионном анализе.</p>
<p>Вся изменчивость наших данных <strong>(total sum of squares, TSS)</strong> определяется так:</p>
<p><span class="math display">\[
\text{TSS} = \sum_{i=1}^n (\bar y - y_i)^2
\]</span></p>
<p>На одной из картинок нам уже встречалась «красная модель» — это и было среднее по выборке. То есть графически TSS выглядит так:</p>
<center>
<img src="pics/tss.jpeg">
</center>
<p>Одну часть этой изменчивости объясняет модель <strong>(explained sum of squares, ESS)</strong>:</p>
<p><span class="math display">\[
\text{ESS} = \sum_{i=1}^n (\bar y - \hat y_i)^2
\]</span></p>
<center>
<img src="pics/ess.jpeg">
</center>
<p>Другую часть этой изменчивости модель не улавливает, и она остаётся необъяснённой (остаточной) <strong>(residual sum of squares, RSS)</strong>:</p>
<p><span class="math display">\[
\text{RSS} = \sum_{i=1}^n (y_i - \hat y_i)^2
\]</span></p>
<center>
<img src="pics/rss.jpeg">
</center>
<p>Очевидно (особенно по графику), что</p>
<p><span class="math display">\[
\text{TSS} = \text{ESS} + \text{RSS}
\]</span></p>
<div class="advanced">
<details>
<summary>
<em>Не очевидно! Ты ещё в прошлый раз обещал пояснить!</em>
</summary>
<p>Поясняю.</p>
<p>Пойдем в лоб по формуле.</p>
<p><span class="math display">\[
\text{TSS} = \sum (y_i - \bar y)^2 = \\
\sum (y_i - \hat y_i + \hat y_i - \bar y)^2 = \\
\sum \big( (y_i - \hat y_i) + (\hat y_i - \bar y_i) \big)^2 = \\
\sum (y_i - \hat y_i)^2 + \sum (\hat y_i - \bar y)^2 + 2 \sum (y_i - \hat y_i) (\hat y_i - \bar y) = \\
\text{RSS} + \text{ESS} + 2 \sum (y_i - \hat y_i) (\hat y_i - \bar y)
\]</span></p>
<p>Ну, норм. Теперь надо доказать, что <span class="math inline">\(\sum (y_i - \hat y_i) (\hat y_i - \bar y)\)</span> всегда равно нулю. Вспомним, что <span class="math inline">\(\hat y_i = b_0 + b_1 x_i\)</span>:</p>
<p><span class="math display">\[
\sum (y_i - \hat y_i) (\hat y_i - \bar y) = \\
\sum (y_i - b_0 - b_1x_i)(b_0 + b_1x_i - \bar y) =
\]</span></p>
<p>Воспользуемся формулой для вычисления <span class="math inline">\(b_0\)</span></p>
<p><span class="math display">\[
b_0 = \bar y - b_1 \bar x
\]</span>
и подставим её в выражение:</p>
<p><span class="math display">\[
= \sum (y_i - \bar y + b_1 \bar x - b_1 x_i) (\bar y - b_1 \bar x + b_1 x_i - \bar y) = \\
\sum \big( (y_i - \bar y) - b_1 (x_i - \bar x) \big) \cdot b_1 (x_i - \bar x) = \\
\sum \big( b_1 (x_i - \bar x) (y_i - \bar y) - b_1^2 (x_i - \bar x)^2 \big) = \\
b_1 \sum (x_i - \bar x) (y_i - \bar y) - b_1^2 \sum (x_i - \bar x)^2 =
\]</span></p>
<p>Теперь вспомним, что</p>
<p><span class="math display">\[
b_1 = \frac{\sum (x_i - \bar x) (y_i - \bar y)}{\sum (x_i - \bar x)^2}
\]</span></p>
<p>Подставим:</p>
<p><span class="math display">\[
= \frac{\Big( \sum (x_i - \bar x) (y_i - \bar y) \Big)^2}{\sum (x_i - \bar x)^2} - \frac{\Big ( \sum (x_i - \bar x) (y_i - \bar y) \Big)^2 \cdot \sum (x_i - \bar x)^2}{\Big( \sum (x_i - \bar x)^2 \Big)^2} = \\
\frac{\Big( \sum (x_i - \bar x) (y_i - \bar y) \Big)^2}{\sum (x_i - \bar x)^2} - \frac{\Big ( \sum (x_i - \bar x) (y_i - \bar y) \Big)^2}{\sum (x_i - \bar x)^2} = 0
\]</span></p>
</details>
</div>
<p>В качестве метрики информативности модели используется <strong>коэффициент детерминации</strong> <span class="math inline">\(R^2\)</span>, который вычисляется по формуле:</p>
<p><span class="math display">\[
R^2 = \frac{\text{ESS}}{\text{TSS}} = 1 - \frac{\text{RSS}}{\text{TSS}},
\]</span></p>
<p>из чего следует, что <span class="math inline">\(0 \leq R^2 \leq 1\)</span>, а значит коэффициент детерминации может быть интерпретирован как <em>доля дисперсии данных, которую смогла объяснить модель</em>.</p>
<p>Считается, что если модель объясняется 0.8 и более дисперсии данных, то она хороша, хотя этот порог о-о-очень сильно зависит от конкретной задачи и исследовательской области.</p>
<p>Кстати, вопрос на подумать: может ли коэффициент детерминации быть отрицательным?</p>
</div>
<div id="simple_reg_significance" class="section level3 hasAnchor" number="14.3.2">
<h3><span class="header-section-number">14.3.2</span> Статистическая значимость модели<a href="simple_linear.html#simple_reg_significance" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>На основе всё тех же сумм квадратов мы можем сделать вывод о том, насколько в целом наша модель статистически значима. Для этого нам надо заняться тестированием некоторой статистической гипотезы. Она формулируется так:</p>
<p><span class="math display">\[
H_0: \beta_0 = \beta_1 = 0 \\
H_1: \beta_0 \neq 0 \vee \beta_1 \neq 0
\]</span></p>
<p>Для тестирования данной гипотезы используется следующая статистика:</p>
<p><span class="math display">\[
F = \frac{\text{MS}_e}{\text{MS}_r} = \frac{\text{ESS} / \mathrm{df_e}}{\text{RSS} / \mathrm{df_r}} \overset{H_0}{\thicksim} F(\mathrm{df_e, df_r}),
\]</span></p>
<p>где <span class="math inline">\(\mathrm{df_e} = p - 1\)</span>, <span class="math inline">\(\mathrm{df_r} = n-p-1\)</span>, <span class="math inline">\(p\)</span> — число предикторов в модели, <span class="math inline">\(n\)</span> — число наблюдений.</p>
<p>Как и всегда, для <span class="math inline">\(F\)</span>-статистики рассчитывается <em>p-value</em>, на основе значения которого мы делаем статистический вывод о статистическом равенстве коэффициента детерминации нулю, а следовательно, о статистической значимости модели в целом.</p>
</div>
<div id="simple_reg_t_test" class="section level3 hasAnchor" number="14.3.3">
<h3><span class="header-section-number">14.3.3</span> Статистическая значимость отдельных предикторов<a href="simple_linear.html#simple_reg_t_test" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Если модель значима в целом, значит среди её коэффициентов есть те, которые статистически отличны от нуля. Иначе говоря, есть такие предикторы, которые значимо связаны с нашей целевой переменной. В случае простой линейной регрессии предиктора всего два — intercept и slope. Intercept не всегда интерпретабелен, поэтому основное внимание уделяют угловому коэффициенту.</p>
<p>Статистическая значимость коэффициента тестируется так:</p>
<p><span class="math display">\[
H_0: \beta_1 = 0 \\
H_1: \beta_1 \neq 0 \\
t = \frac{b_1 - \beta_1}{\text{SE}_{b_1}} = \frac{b_1}{\text{SE}_{b_1}} \overset{H_0}{\thicksim} t(\text{df} = n-p-1),
\]</span></p>
<p>где <span class="math inline">\(\text{SE}_{b_1} = \frac{s_r}{\sum_{i=1}^n (x_i - \bar x)^2}\)</span>, <span class="math inline">\(s_r^2 = \frac{\sum_{i=1}^n (y_i - \hat y)^2}{n-2}\)</span></p>
<p>Хвала небесам, оно все считается само.</p>
</div>
<div id="simple_regression_results" class="section level3 hasAnchor" number="14.3.4">
<h3><span class="header-section-number">14.3.4</span> Результаты регрессионного анализа<a href="simple_linear.html#simple_regression_results" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Посмотрим на данные из индустрии. У нас есть данные некоторой компании, в которых есть переменная <code>fot</code> (ФОТ — фонд оплаты труда) и переменная <code>grade_score</code> (интегральный балл по грейду). С первой всё ясно — количество денег, которое заложено на оплату труда сотрудника. Со второй переменной всё чуть сложнее — это оценка сотрудника, рассчитываемая по некоторой схеме, неизвестной нам, ибо NDA<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>.</p>
<p>Ну, да бох с ним, как там этот грейд рассчитывается. Нам ведь для построения регрессии важно что — чтобы была некоторая <em>целевая</em> количественная переменная, и некоторый <em>предиктор</em>, тоже количественный. У нас есть и то, и другое.</p>
<p>Посмотрим на связь двух переменных:</p>
<p><img src="SFDA_files/figure-html/scatteprplot_grade-1.png" width="672" /></p>
<p>Картинка местами прикольная и даже забавная, но в целом мы наблюдаем некоторую положительную взаимосвязь между переменными, линия тренда с положительным наклоном — норм, можно пытаться это всё дело моделировать.</p>
<p>Регрессионный анализ нам покажет что-то такое:</p>
<pre><code>## 
## Call:
## lm(formula = fot ~ grade_score, data = ds)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -171435  -28467   -3305   15470  418192 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -7.483e+04  3.358e+03  -22.28   &lt;2e-16 ***
## grade_score  1.118e+00  2.433e-02   45.98   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 47450 on 1993 degrees of freedom
## Multiple R-squared:  0.5147, Adjusted R-squared:  0.5145 
## F-statistic:  2114 on 1 and 1993 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Таблица невероятно похожа на результаты дисперсионного анализа, не так ли? Падазритильна…</p>
<p>Некоторые отличия, конечно, есть — пройдемся по колонкам:</p>
<ul>
<li><code>Estimate</code> — оценка коэффициента при нашем предикторе, то есть <span class="math inline">\(b_1\)</span></li>
<li><code>Std. Error</code> — стандартная ошибка коэффициента (нужна для вычисления следующей колонки)</li>
<li><code>t value</code> — t-статистика, используемая для тестирования статистической значимости предиктора
<ul>
<li>это уже знакомый нам t-тест, который был в корреляционном анализе</li>
</ul></li>
<li><code>Pr(&gt;|t|)</code> — это так обозвали <em>p-value</em>, которые рассчитывается для t-статистики</li>
</ul>
<p>Кроме таблицы, нам нужны еще две последние строчки, в которых указан <span class="math inline">\(R^2\)</span> и <span class="math inline">\(F\)</span>-статистика со своим <em>p-value</em>.</p>
<p>Что можно заключить по результатам анализа?</p>
<ul>
<li>Во-первых, что модель в целом статистически значима (<em>F</em>(1, 1993) = 2114, <em>p</em> &lt; .001) и объясняет 51% дисперсии данных.</li>
<li>Во-вторых, что предиктор модели (<code>grade_score</code>, интегральный балл по грейду) также статистически значим.</li>
</ul>
<p>Ну, красота.</p>
</div>
<div id="slope_interpretation_simple_linear" class="section level3 hasAnchor" number="14.3.5">
<h3><span class="header-section-number">14.3.5</span> Интерпретация коэффициента при предикторе<a href="simple_linear.html#slope_interpretation_simple_linear" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>— А ежели наш предиктор значим, то это же получается, что коэффициент при нем статистически отличен от нуля?<br>
— Да, именно так.<br>
— А можем ли мы его каким-либо образом содержательно проинтерпретировать?<br>
— Да.<br>
— А как?<br>
— Ровно так, как [возможно] говорили на математике.</p>
<p>Вообще угловой коэффициент показывает, <em>на сколько изменится целевая переменная при увеличении предиктора на единицу</em>. Поэтому мы можем сказать, что при увеличении ингерального балла по грейду на единицу фонд оплаты труда сотрудника возрастает на 1118₽.</p>
<p>Дорого-богато.</p>
</div>
</div>
<div id="simple_reg_diagnostics" class="section level2 hasAnchor" number="14.4">
<h2><span class="header-section-number">14.4</span> Диагностика модели<a href="simple_linear.html#simple_reg_diagnostics" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Окей, наша модель значима в целом, а значит значимы и её предикторы, она объясняет приемлемую долю дисперсии данных. Неужели этого недостаточно?</p>
<p>Недостаточно. При построении модели мы исходили из ряда предпосылок. Напомним их:</p>
<ul>
<li>линейность связи</li>
<li>нормальность распределения остатков и нулевое математическое ожидание</li>
<li>равенствво дисперсии остатков при различных значениях предикторов (гомоскедастичность)</li>
<li>независимость остатков от предикторов модели</li>
</ul>
<p>Линейность связи можно проверить визуализацией корреляции между переменными.</p>
<p>Другие предпосылки мы можем проверить с помощью диагностических графиков.</p>
<p><img src="SFDA_files/figure-html/diagnostics_simple_linear-1.png" width="672" /><img src="SFDA_files/figure-html/diagnostics_simple_linear-2.png" width="672" /><img src="SFDA_files/figure-html/diagnostics_simple_linear-3.png" width="672" /><img src="SFDA_files/figure-html/diagnostics_simple_linear-4.png" width="672" /></p>
<p>Данные графики позволяют провести диагностику модели.</p>
<p>Нормальность распределения остатков отображена на втором графике (<em>Normal Q-Q</em>). Если все наблюдения находятся на или близко к пунктирной линии, то распределение остатков не отличается от нормального. В данном случае мы наблюдаем, что в области верхних квантилей (правая второна графика) остатки модели начинают ползти вверх — значит наша модель не до конца ухватывает имеющуюся закономерность.</p>
<p>Первый (<em>Residual vs Fitted</em>) и третий (<em>Scale-Location</em>) графики позволяют проверить независимость остатков от предикторов модели и требование гомоскедастичности. На графике не должно определяться никаких явных паттернов. В данном случае мы видим, что на первом графике (<em>Residual vs Fitted</em>) разброс остатков по мере движения по оси <span class="math inline">\(x\)</span> слева направо постепенно увеличивается — не выполнено требование гомоскедастичности. На третьем графике (<em>Scale-Location</em>) выявляется паттерн линейной связи (обратите внимание на расположение красной линии), что говорит о том, что требование независимости остатков модели от предикторов не выполнено. Итого, вновь модель не до конца ухватывает имеющиеся закономерности.</p>
<p>Последний график позволяет определить влиятельные наблюдения. Это такие наблюдения, удаление/добавление которых сильно повлияет на положение регрессионной прямой. В данном случае все наблюдения располагаются в пределах критических значений (серая пунктирная линия в правом верхнем углу).</p>
<p>Что можно заключить по результатам диагностики модели? Модель необходимо дорабатывать. Она ловит часть закономерности, присутствующей в данных, но необходимо вводить дополнительные предикторы, чтобы регрессия ухватывала имеющуюся закономерность более полно.</p>
</div>
<div id="corr_vs_lm" class="section level2 hasAnchor" number="14.5">
<h2><span class="header-section-number">14.5</span> Корреляция vs регрессия<a href="simple_linear.html#corr_vs_lm" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Есть некоторый регрессионный хайп о том, что «корреляция — отстой метод, и регрессия — кул». Методы, действительно похожи, однако попробуем разобраться, что к чему.</p>
<ul>
<li><strong>Сходства</strong>
<ul>
<li>Оба метода тестируют гипотезы о связях
<ul>
<li>Если мы не имеет дела с экспериментальным дизайном — там предшествование во времени и отсутствие третьих переменных контролируется именно на уровне дизайна, что позволяет нам делать причинно-следственные связи</li>
</ul></li>
<li>Оба метода — корреляция и простая линейная регрессия — работают с количественными переменными</li>
</ul></li>
<li><strong>Различия</strong>
<ul>
<li>Корреляция нам дает только количественное выражение силы и направления связи. Регрессия строит модель, которую мы можем использовать для предсказаний на новых данных.</li>
<li>Корреляция позволяет тестировать гипотезу о связях <em>только между двумя</em> переменными. Регрессия позволяет включать в модель <em>несколько</em> предикторов.</li>
</ul></li>
</ul>
<p>Итого, если у вы работаете только с двумя переменными, в целом, решительно всё равно, делаете вы корреляционный анализ или регрессионный. Конечно, если у вас стоит исследовательская задача, а не предиктиквная — тогда регрессия. Если же вы хотите изучать более сложные закономерности, то добро пожаловать в следующую главу.</p>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>Non-disclosure agreement, соглашение о неразглашении.<a href="simple_linear.html#fnref1" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="post_hoc.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="multiple_linear.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["SFDA.pdf", "SFDA.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
