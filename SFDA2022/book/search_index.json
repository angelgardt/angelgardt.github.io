[["nhst.html", "8 Тестирование статистических гипотех 8.1 Базовые понятия 8.2 Возможные результаты проверки гипотез 8.3 Асимметрия статистического вывода 8.4 Алгоритм тестирования статистических гипотез", " 8 Тестирование статистических гипотех В ходе статистического анализа мы, главным образом, заняты тем, что тестируем статистические гипотезы. Ведь на какого рода вопросы мы отвечаем с помощью анализа? Различаются ли группы между собой? Значимо ли влияние какого-либо фактора? → Различаются ли группы между собой? Хороша ли та модель, которую мы построили? → Отличается ли она от нулевой модели? И так далее. Так или иначе, всё сводится в тому, что мы ищем какие-то различия. Но силу того, что у нас неопределённость и вариация в данных, мы просто так «в лоб» сказать о различиях по оценкам параметров не можем. Приходится тестировать статистические гипотезы. 8.1 Базовые понятия Гипотеза (\\(H\\)) — это предположение, которое подлежит проверке на основе результатов наблюдений. Гипотезы бывают трех видов: Теоретическая — про конструкты. Эмпирическая — про переменные (зависимые и независимые). Статистическая — про данные (что мы получили в данный конкретный момент, собрав вот эти конкретные данные). Статистические гипотезы бывают простыми и сложными. Простая гипотеза — это такое предположение, которое включает в себя какое-либо однозначно определеяемое утверждение. Например, истинная величина параметра соответствует некоторому строго заданному значению: \\(H:\\theta = \\theta_0\\). Другой вариант — две генеральные совокупности имеют одно и то же значение одной и той же характеристики: \\(H:\\theta_1 = \\theta_2\\). Сложная гипотеза предполагает множественность вариантов для параметра, которые укладываются в рамки проверяемого предположения. Например, \\(H:\\theta &gt; \\theta_0\\) или \\(H:\\theta_1 \\neq \\theta_2\\). В рамках самого хода тестирования гипотез существует проверяемая (нулевая) гипотеза (\\(H_0\\)). Её обычно стараются предельно упростить, поэтому она формулируется как простая гипотеза. В противовес ей выдвигается альтернативная гипотеза (\\(H_1\\)), которая будет иметь вид сложной гипотезы. Для проверки гипотезы нужны две вещи: результаты наблюдений и критерий. Результаты наблюдений, полученные на выборке, сами по себе, как правило, не используются. Однако на их основе рассчитываются выборочные статистики (показатели), которые непосредственно участвуют в проверке гипотезы. В результате проверки статистических гипотез могут возникнуть четыре ситуации. 8.2 Возможные результаты проверки гипотез Мы изучаем в исследовании какую-либо закономерность, которая в реальном мире может существовать, а может и не существовать. В силу неопределённости и вариативности наших данных мы может либо обнаружить интересующую нас закономерность, либо не обнаружить. В качестве нулевой гипотезы мы выдвигаем предположение о том, что закономерность отсутствует — так мы упрощаем нашу нулевую гипотезу. Пусть \\(H_0\\) обозначает, что предположение, которое мы проверяем справедливо, а \\(H_1\\) — не справедливо. На основании данных мы можем либо не отклонить наше предположение (\\(\\hat H_0\\)), либо отклонить (\\(\\hat H_1\\)). Тогда имеем следующую ситуацию: \\(H_0\\) \\(H_1\\) \\(\\hat H_0\\) ✓ Ошибка II рода \\(\\hat H_1\\) Ошибка I рода ✓ Ошибка I рода возникает, когда в генеральной совокупности искомой закономерности нет, но мы в силу случайных флуктуаций в данных её нашли. Ошибка II рода возникает, когда в генеральной совокупности искомая закономерность есть, но мы в силу каких-либо причин её не нашли. Ошибки — это нехорошо, они нас не устраивают. Надо каким-то образом их контролировать. Ошибка I рода контролируется достаточно просто. Так как мы нашли закономерность, которую искали, мы можем посчитать вероятность, с которой потенциально ошиблись. А собственно контролировать ошибку мы будем с помощью уровня значимости \\(\\alpha\\), который выбирается до начала процедуры тестирования гипотезы. Он и задает вероятность, с который мы позволяем себе ошибиться — отклонить нулевую гипотезу, при условии, что она верна. Ошибку II рода контролировать сложнее, так как мы не нашли закономерность, которую искали. Нам нужна какая-то метрика, которая позволит сказать, что мы сделали всё возможное для того, чтобы обнаружить искомую закономерность. Вероятность ошибки II рода обозначается \\(\\beta\\) — тогда вероятность того, что мы не совершили ошибку II рода будет \\(1 - \\beta\\). Эта величина называется статистической мощностью, и она связана с размером эффекта и объемом выборки. Статистическую мощность можно рассчитать как до проведения статистического анализа — для расчета требуемого объема выборки — так и после — для определения достигнутой статистической мощности. Соберем все обозначения в единую табличку1: \\(H_0\\) \\(H_1\\) \\(\\hat H_0\\) \\(\\mathrm P (\\hat H_0 | H_0)\\) \\(\\mathrm P (\\hat H_0 | H_1) = \\beta\\) \\(\\hat H_1\\) \\(\\mathrm P (\\hat H_1 | H_0) = \\alpha\\) \\(\\mathrm P (\\hat H_1 | H_1) = 1 - \\beta\\) Уровень значимости \\(\\alpha\\) выбирается близким к нулю — всем знакомо конвенциональное значение \\(0.05\\). Вообще \\(\\alpha\\) можно выбрать сколь угодно малым, однако при выборе уровня значимости руководствуются принципом разумной достаточности, так как если устремить \\(\\alpha\\) к нулю, то устремиться к нулю и вероятность отклонения нулевой гипотезы Математические руны \\[ \\mathrm P (\\hat H_1) = \\mathrm P (\\hat H_1 | H_0) \\cdot \\mathrm P (H_0) = \\alpha \\cdot \\mathrm P(H_0) \\] Достаточной статистической мощностью считается \\(0.8\\). Аналогично, устремляя мощность к единице (\\((1 - \\beta) \\rightarrow 1 \\Rightarrow \\beta \\rightarrow 0\\)), мы устремляем вероятность не отклонения нулевой гипотезы к нулю: Ещё математические руны \\[ \\mathrm P (\\hat H_0) = \\mathrm P (\\hat H_0 | H_1) \\cdot \\mathrm P (H_1) = \\beta \\cdot \\mathrm P (H_1) \\] Необходимо также помнить, что ошибки первого и второго рода связаны между собой так, что \\[ \\alpha \\rightarrow 0 \\Rightarrow \\beta \\rightarrow 1 \\] Опять математические руны \\[ \\beta \\cdot \\mathrm P (H_1) = \\mathrm P (\\hat H_0) = \\mathrm P (\\hat H_0 | H_0) \\cdot \\mathrm P (H_0) \\Rightarrow \\beta = \\frac{1}{\\mathrm P (H_1)} \\cdot \\mathrm P (H_0) \\cdot \\mathrm P(\\hat H_0 | H_0) \\\\ \\beta = \\frac{1}{\\mathrm P (H_1)} \\cdot \\big (1 - \\mathrm P (H_1 | H_0)\\big) = \\frac{1}{\\mathrm P (H_1)} \\cdot \\mathrm P (H_0) \\cdot (1 - \\alpha) \\] 8.3 Асимметрия статистического вывода Выше мы сказали, что для проверки гипотезы нужны две вещи: результаты наблюдений и критерий. С результатами наблюдений более-менее очевидно. Критерий — это правило, согласно которому гипотезу либо принимают, либо отклоняют. Однако перед тем как проверять гипотезу, её так-то нужно сформулировать, и сделать это правильно, поскольку от формулировки гипотезы зависит интерпретация результатов проверки и дальнейшее использование полученной информации. Используемая статистика сама по себе является [непрерывной] случайной величиной, а значит может быть построено её распределение. Критерий будет разделять это распределение на непересекающиеся области. В результате чего возникает критическая область — область отклонения гипотезы. Дополнением к ней является область неотклонения гипотезы. Критическая область может быть односторонней (при \\(H_1:\\theta &gt; \\theta_0\\) или \\(H_1: \\theta &lt; \\theta_0\\)) и двусторонней (при \\(H_1:\\theta \\neq \\theta_0\\)). «Размер» критической области определяется уровнем значимости. Статистический вывод — заключение о том, получили ли мы подтверждение альтернативной гипотезы — по структуре представляет собой импликацию. Если вам не знаком этот термин из логики, то вот: Если значение нашей статистики, которое мы рассчитали на выборке, попало в критическую область, то мы говорим о том, что нулевая гипотеза отклоняется. Если значение нашей статистики, которое мы рассчитали на выборке, не попало в критическую область, то мы не получаем оснований для того, чтобы отклонить нулевую гипотезу. Однако мы также не получаем оснований, чтобы её «принять». Мы остаёмся в некотором неведении: мы не нашли различий, а есть они там или нет — хто ж их знает… Итого, мы не можем сделать никакого вывода. В этом и заключается асимметрия статистического вывода. Как раз для того, чтобы с ней как-то жить, мы работаем со статистической мощностью. Посмотреть, как все эти штуки друг с другом соотносятся можно тут. 8.4 Алгоритм тестирования статистических гипотез Для тестирования гипотез есть два сценария: первый и тот, которым мы будем пользоваться. Первый вариант чуть более классический, второй — более гибкий. Сценарий номер раз Формулировка гипотезы Выбор статистического критерия Выбор уровня значимости \\(\\alpha\\) Построение закона распредления статистики критерия при условии, что нулевая гипотеза верна Определение границ критической области Расчёт выборочной статистики Определение, попадает ли наблюдемое значение статистики в критическую область и вынесение решения Сценарий номер два Формулировка гипотезы Выбор статистического критерия Выбор уровня значимости \\(\\alpha\\) Построение закона распредлеения статистики критерия при условии, что нулевая гипотеза верна Расчёт выборочной статистики Расчёт достигнутого уровня значимости p-value Сопоставление \\(\\alpha\\) и p-value и вынесение решения Почему второй вариант более гибкий? Представим, что мы захотели понизить уровень значимости с \\(0.05\\) до \\(0.01\\) — такие уровни значимости всречаются, например, в медицине. Если мы идем по первому сценарию, то нам надо заново пересчитать критические значения и вновь проанализировать, попадает ли наблюдаемое значение в критическую область. Если мы адепты второго сценария, то нам надо только выполнить одно новое сравнение нашего p-value с новым уровнем значимости. Вероятно, пока мало что понятно. Поэтому в следующей главе разберем все это безобразие на примере. Здесь использовано обозначение условной вероятности \\(\\mathrm P(A|B)\\), то есть это вероятность того, что случилось событие \\(A\\) при условии, что случилось событие \\(B\\).↩︎ "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
